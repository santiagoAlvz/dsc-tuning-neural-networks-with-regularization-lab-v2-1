{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Tuning Neural Networks with Regularization - Lab \n","\n","## Introduction\n","\n","In this lab, you'll use a train-test partition as well as a validation set to get better insights about how to tune neural networks using regularization techniques. You'll start by repeating the process from the last section: importing the data and performing preprocessing including one-hot encoding. From there, you'll define and compile the model like before. \n","\n","## Objectives\n","\n","You will be able to:\n","\n","- Apply early stopping criteria with a neural network \n","- Apply L1, L2, and dropout regularization on a neural network  \n","- Examine the effects of training with more data on a neural network  \n","\n","\n","## Load the Data\n","\n","Run the following cell to import some of the libraries and classes you'll need in this lab. "]},{"cell_type":"code","execution_count":67,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import random\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","from sklearn.model_selection import train_test_split\n","from keras.utils.np_utils import to_categorical\n","from sklearn.preprocessing import LabelBinarizer\n","from keras.preprocessing.text import Tokenizer\n","\n","import warnings\n","warnings.filterwarnings(action='ignore', category=FutureWarning)"]},{"cell_type":"markdown","metadata":{},"source":["The data is stored in the file `'Bank_complaints.csv'`. Load and preview the dataset."]},{"cell_type":"code","execution_count":68,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Product</th>\n","      <th>Consumer complaint narrative</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Student loan</td>\n","      <td>In XX/XX/XXXX I filled out the Fedlaon applica...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Student loan</td>\n","      <td>I am being contacted by a debt collector for p...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Student loan</td>\n","      <td>I cosigned XXXX student loans at SallieMae for...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Student loan</td>\n","      <td>Navient has sytematically and illegally failed...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Student loan</td>\n","      <td>My wife became eligible for XXXX Loan Forgiven...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        Product                       Consumer complaint narrative\n","0  Student loan  In XX/XX/XXXX I filled out the Fedlaon applica...\n","1  Student loan  I am being contacted by a debt collector for p...\n","2  Student loan  I cosigned XXXX student loans at SallieMae for...\n","3  Student loan  Navient has sytematically and illegally failed...\n","4  Student loan  My wife became eligible for XXXX Loan Forgiven..."]},"execution_count":68,"metadata":{},"output_type":"execute_result"}],"source":["# Load and preview the dataset\n","df = pd.read_csv('Bank_complaints.csv')\n","df.head()"]},{"cell_type":"markdown","metadata":{},"source":["## Preprocessing Overview\n","\n","Before you begin to practice some of your new tools such as regularization and optimization, let's practice munging some data as you did in the previous section with bank complaints. Recall some techniques:\n","\n","* Sampling in order to reduce training time (investigate model accuracy vs data size later on)\n","* Train - test split\n","* One-hot encoding your complaint text\n","* Transforming your category labels \n","\n","## Preprocessing: Generate a Random Sample\n","\n","Since you have quite a bit of data and training neural networks takes a substantial amount of time and resources, downsample in order to test your initial pipeline. Going forward, these can be interesting areas of investigation: how does your model's performance change as you increase (or decrease) the size of your dataset?  \n","\n","- Generate a random sample of 10,000 observations using seed 123 for consistency of results. \n","- Split this sample into `X` and `y` "]},{"cell_type":"code","execution_count":69,"metadata":{},"outputs":[],"source":["# Downsample the data\n","df_sample = df.sample(10000, random_state=123)\n","\n","# Split the data into X and y\n","y = df_sample['Product']\n","X = df_sample['Consumer complaint narrative']"]},{"cell_type":"markdown","metadata":{},"source":["## Train-test split\n","\n","- Split the data into training and test sets \n","- Assign 1500 obervations to the test set and use 42 as the seed "]},{"cell_type":"code","execution_count":70,"metadata":{},"outputs":[],"source":["# Split data into training and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1500, random_state=42)"]},{"cell_type":"markdown","metadata":{},"source":["## Validation set \n","\n","As mentioned in the previous lesson, it is good practice to set aside a validation set, which is then used during hyperparameter tuning. Afterwards, when you have decided upon a final model, the test set can then be used to determine an unbiased perforance of the model. \n","\n","Run the cell below to further divide the training data into training and validation sets. "]},{"cell_type":"code","execution_count":71,"metadata":{},"outputs":[],"source":["# Split the data into training and validation sets\n","X_train_final, X_val, y_train_final, y_val = train_test_split(X_train, y_train, test_size=1000, random_state=42)"]},{"cell_type":"markdown","metadata":{},"source":["## Preprocessing: One-hot Encoding the Complaints\n","\n","As before, you need to do some preprocessing before building a neural network model. \n","\n","- Keep the 2,000 most common words and use one-hot encoding to reformat the complaints into a matrix of vectors \n","- Transform the training, validate, and test sets "]},{"cell_type":"code","execution_count":72,"metadata":{},"outputs":[],"source":["# Use one-hot encoding to reformat the complaints into a matrix of vectors \n","# Only keep the 2000 most common words \n","\n","tokenizer = Tokenizer(num_words=2000)\n","\n","\n","X_train_tokens = tokenizer.texts_to_matrix(X_train_final, mode='binary')\n","X_val_tokens = tokenizer.texts_to_matrix(X_val, mode='binary')\n","X_test_tokens = tokenizer.texts_to_matrix(X_test, mode='binary')"]},{"cell_type":"markdown","metadata":{},"source":["## Preprocessing: Encoding the Products\n","\n","Similarly, now transform the descriptive product labels to integers labels. After transforming them to integer labels, retransform them into a matrix of binary flags, one for each of the various product labels.  \n","  \n","> **Note**: This is similar to your previous work with dummy variables. Each of the various product categories will be its own column, and each observation will be a row. In turn, each of these observation rows will have a 1 in the column associated with it's label, and all other entries for the row will be zero. \n","\n","Transform the training, validate, and test sets. "]},{"cell_type":"code","execution_count":73,"metadata":{},"outputs":[],"source":["# Transform the product labels to numerical values\n","lb = LabelBinarizer()\n","lb.fit(y_train_final)\n","\n","y_train_lb = to_categorical(lb.transform(y_train_final))[:, :, 1]\n","y_val_lb = to_categorical(lb.transform(y_val))[:, :, 1]\n","y_test_lb = to_categorical(lb.transform(y_test))[:, :, 1]"]},{"cell_type":"markdown","metadata":{},"source":["## A Baseline Model \n","\n","Rebuild a fully connected (Dense) layer network:  \n","- Use 2 hidden layers with 50 units in the first and 25 in the second layer, both with `'relu'` activation functions (since you are dealing with a multiclass problem, classifying the complaints into 7 classes) \n","- Use a `'softmax'` activation function for the output layer  "]},{"cell_type":"code","execution_count":74,"metadata":{},"outputs":[],"source":["# Build a baseline neural network model using Keras\n","random.seed(123)\n","from keras import models\n","from keras import layers\n","\n","baseline_model = models.Sequential()\n","\n","baseline_model.add(layers.Dense(50, activation='relu', input_shape=(2000,)))\n","baseline_model.add(layers.Dense(25, activation='relu'))\n","baseline_model.add(layers.Dense(7, activation='softmax'))"]},{"cell_type":"markdown","metadata":{},"source":["### Compile the Model\n","\n","Compile this model with: \n","\n","- a stochastic gradient descent optimizer \n","- `'categorical_crossentropy'` as the loss function \n","- a focus on `'accuracy'` "]},{"cell_type":"code","execution_count":75,"metadata":{},"outputs":[],"source":["# Compile the model\n","baseline_model.compile(\n","    optimizer='SGD',\n","    loss='categorical_crossentropy',\n","    metrics=['acc']\n",")"]},{"cell_type":"markdown","metadata":{},"source":["### Train the Model\n","\n","- Train the model for 150 epochs in mini-batches of 256 samples \n","- Include the `validation_data` argument to ensure you keep track of the validation loss  "]},{"cell_type":"code","execution_count":76,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/150\n","30/30 [==============================] - 0s 5ms/step - loss: 1.9452 - acc: 0.1872 - val_loss: 1.9446 - val_acc: 0.1740\n","Epoch 2/150\n","30/30 [==============================] - 0s 4ms/step - loss: 1.9438 - acc: 0.1884 - val_loss: 1.9435 - val_acc: 0.1740\n","Epoch 3/150\n","30/30 [==============================] - 0s 4ms/step - loss: 1.9425 - acc: 0.1884 - val_loss: 1.9424 - val_acc: 0.1740\n","Epoch 4/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9413 - acc: 0.1884 - val_loss: 1.9414 - val_acc: 0.1740\n","Epoch 5/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9402 - acc: 0.1884 - val_loss: 1.9406 - val_acc: 0.1740\n","Epoch 6/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9392 - acc: 0.1884 - val_loss: 1.9397 - val_acc: 0.1740\n","Epoch 7/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9383 - acc: 0.1884 - val_loss: 1.9390 - val_acc: 0.1740\n","Epoch 8/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9375 - acc: 0.1884 - val_loss: 1.9383 - val_acc: 0.1740\n","Epoch 9/150\n","30/30 [==============================] - 0s 4ms/step - loss: 1.9367 - acc: 0.1884 - val_loss: 1.9377 - val_acc: 0.1740\n","Epoch 10/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9360 - acc: 0.1884 - val_loss: 1.9372 - val_acc: 0.1740\n","Epoch 11/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9353 - acc: 0.1884 - val_loss: 1.9367 - val_acc: 0.1740\n","Epoch 12/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9347 - acc: 0.1884 - val_loss: 1.9362 - val_acc: 0.1740\n","Epoch 13/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9341 - acc: 0.1884 - val_loss: 1.9358 - val_acc: 0.1740\n","Epoch 14/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9336 - acc: 0.1884 - val_loss: 1.9354 - val_acc: 0.1740\n","Epoch 15/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9332 - acc: 0.1884 - val_loss: 1.9351 - val_acc: 0.1740\n","Epoch 16/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9328 - acc: 0.1884 - val_loss: 1.9348 - val_acc: 0.1740\n","Epoch 17/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9324 - acc: 0.1884 - val_loss: 1.9345 - val_acc: 0.1740\n","Epoch 18/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9320 - acc: 0.1884 - val_loss: 1.9342 - val_acc: 0.1740\n","Epoch 19/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9317 - acc: 0.1884 - val_loss: 1.9340 - val_acc: 0.1740\n","Epoch 20/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9314 - acc: 0.1884 - val_loss: 1.9338 - val_acc: 0.1740\n","Epoch 21/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9311 - acc: 0.1884 - val_loss: 1.9336 - val_acc: 0.1740\n","Epoch 22/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9308 - acc: 0.1884 - val_loss: 1.9335 - val_acc: 0.1740\n","Epoch 23/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9306 - acc: 0.1884 - val_loss: 1.9333 - val_acc: 0.1740\n","Epoch 24/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9304 - acc: 0.1884 - val_loss: 1.9332 - val_acc: 0.1740\n","Epoch 25/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9302 - acc: 0.1884 - val_loss: 1.9330 - val_acc: 0.1740\n","Epoch 26/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9300 - acc: 0.1884 - val_loss: 1.9329 - val_acc: 0.1740\n","Epoch 27/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9298 - acc: 0.1884 - val_loss: 1.9328 - val_acc: 0.1740\n","Epoch 28/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9297 - acc: 0.1884 - val_loss: 1.9327 - val_acc: 0.1740\n","Epoch 29/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9295 - acc: 0.1884 - val_loss: 1.9326 - val_acc: 0.1740\n","Epoch 30/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9294 - acc: 0.1884 - val_loss: 1.9325 - val_acc: 0.1740\n","Epoch 31/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9293 - acc: 0.1884 - val_loss: 1.9325 - val_acc: 0.1740\n","Epoch 32/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9292 - acc: 0.1884 - val_loss: 1.9324 - val_acc: 0.1740\n","Epoch 33/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9291 - acc: 0.1884 - val_loss: 1.9323 - val_acc: 0.1740\n","Epoch 34/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9290 - acc: 0.1884 - val_loss: 1.9323 - val_acc: 0.1740\n","Epoch 35/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9289 - acc: 0.1884 - val_loss: 1.9322 - val_acc: 0.1740\n","Epoch 36/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9288 - acc: 0.1884 - val_loss: 1.9322 - val_acc: 0.1740\n","Epoch 37/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9287 - acc: 0.1884 - val_loss: 1.9321 - val_acc: 0.1740\n","Epoch 38/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9287 - acc: 0.1884 - val_loss: 1.9321 - val_acc: 0.1740\n","Epoch 39/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9286 - acc: 0.1884 - val_loss: 1.9321 - val_acc: 0.1740\n","Epoch 40/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9285 - acc: 0.1884 - val_loss: 1.9321 - val_acc: 0.1740\n","Epoch 41/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9285 - acc: 0.1884 - val_loss: 1.9320 - val_acc: 0.1740\n","Epoch 42/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9284 - acc: 0.1884 - val_loss: 1.9320 - val_acc: 0.1740\n","Epoch 43/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9284 - acc: 0.1884 - val_loss: 1.9320 - val_acc: 0.1740\n","Epoch 44/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9284 - acc: 0.1884 - val_loss: 1.9320 - val_acc: 0.1740\n","Epoch 45/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9283 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 46/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9283 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 47/150\n","30/30 [==============================] - 0s 4ms/step - loss: 1.9283 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 48/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9282 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 49/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9282 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 50/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9282 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 51/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9281 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 52/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9281 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 53/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9281 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 54/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9281 - acc: 0.1884 - val_loss: 1.9318 - val_acc: 0.1740\n","Epoch 55/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9281 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 56/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9280 - acc: 0.1884 - val_loss: 1.9318 - val_acc: 0.1740\n","Epoch 57/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9280 - acc: 0.1884 - val_loss: 1.9318 - val_acc: 0.1740\n","Epoch 58/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9280 - acc: 0.1884 - val_loss: 1.9318 - val_acc: 0.1740\n","Epoch 59/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9280 - acc: 0.1884 - val_loss: 1.9318 - val_acc: 0.1740\n","Epoch 60/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9280 - acc: 0.1884 - val_loss: 1.9318 - val_acc: 0.1740\n","Epoch 61/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9280 - acc: 0.1884 - val_loss: 1.9318 - val_acc: 0.1740\n","Epoch 62/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9280 - acc: 0.1884 - val_loss: 1.9318 - val_acc: 0.1740\n","Epoch 63/150\n","30/30 [==============================] - 0s 5ms/step - loss: 1.9280 - acc: 0.1884 - val_loss: 1.9318 - val_acc: 0.1740\n","Epoch 64/150\n","30/30 [==============================] - 0s 4ms/step - loss: 1.9280 - acc: 0.1884 - val_loss: 1.9318 - val_acc: 0.1740\n","Epoch 65/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9279 - acc: 0.1884 - val_loss: 1.9318 - val_acc: 0.1740\n","Epoch 66/150\n","30/30 [==============================] - 0s 4ms/step - loss: 1.9279 - acc: 0.1884 - val_loss: 1.9318 - val_acc: 0.1740\n","Epoch 67/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9279 - acc: 0.1884 - val_loss: 1.9318 - val_acc: 0.1740\n","Epoch 68/150\n","30/30 [==============================] - 0s 5ms/step - loss: 1.9279 - acc: 0.1884 - val_loss: 1.9318 - val_acc: 0.1740\n","Epoch 69/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9279 - acc: 0.1884 - val_loss: 1.9318 - val_acc: 0.1740\n","Epoch 70/150\n","30/30 [==============================] - 0s 4ms/step - loss: 1.9279 - acc: 0.1884 - val_loss: 1.9318 - val_acc: 0.1740\n","Epoch 71/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9279 - acc: 0.1884 - val_loss: 1.9318 - val_acc: 0.1740\n","Epoch 72/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9279 - acc: 0.1884 - val_loss: 1.9318 - val_acc: 0.1740\n","Epoch 73/150\n","30/30 [==============================] - 0s 2ms/step - loss: 1.9279 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 74/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9279 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 75/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9279 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 76/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9279 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 77/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9279 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 78/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9279 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 79/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9279 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 80/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9279 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 81/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9279 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 82/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9279 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 83/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9279 - acc: 0.1884 - val_loss: 1.9320 - val_acc: 0.1740\n","Epoch 84/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9279 - acc: 0.1884 - val_loss: 1.9320 - val_acc: 0.1740\n","Epoch 85/150\n","30/30 [==============================] - 0s 5ms/step - loss: 1.9279 - acc: 0.1884 - val_loss: 1.9320 - val_acc: 0.1740\n","Epoch 86/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9279 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 87/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9279 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 88/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9320 - val_acc: 0.1740\n","Epoch 89/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9279 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 90/150\n","30/30 [==============================] - 0s 4ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 91/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 92/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 93/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 94/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 95/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 96/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 97/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 98/150\n","30/30 [==============================] - 0s 4ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 99/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 100/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 101/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 102/150\n","30/30 [==============================] - 0s 4ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 103/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 104/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 105/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 106/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 107/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 108/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 109/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 110/150\n","30/30 [==============================] - 0s 4ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 111/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 112/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 113/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 114/150\n","30/30 [==============================] - 0s 5ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 115/150\n","30/30 [==============================] - 0s 4ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 116/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 117/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 118/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 119/150\n","30/30 [==============================] - 0s 4ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 120/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 121/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 122/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 123/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 124/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 125/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 126/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 127/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 128/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 129/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 130/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 131/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 132/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 133/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9320 - val_acc: 0.1740\n","Epoch 134/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9320 - val_acc: 0.1740\n","Epoch 135/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 136/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 137/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9320 - val_acc: 0.1740\n","Epoch 138/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9320 - val_acc: 0.1740\n","Epoch 139/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 140/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 141/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 142/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 143/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 144/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 145/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 146/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 147/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 148/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 149/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 150/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n"]}],"source":["# Train the model\n","baseline_model_val = baseline_model.fit(X_train_tokens,\n","                                        y_train_lb,\n","                                        epochs=150,\n","                                        batch_size=256,\n","                                        validation_data=(X_val_tokens, y_val_lb))"]},{"cell_type":"markdown","metadata":{},"source":["### Model Performance\n","\n","The attribute `.history` (stored as a dictionary) contains four entries now: one per metric that was being monitored during training and validation. Print the keys of this dictionary for confirmation: "]},{"cell_type":"code","execution_count":77,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["dict_keys(['loss', 'acc', 'val_loss', 'val_acc'])\n"]}],"source":["# Access the history attribute and store the dictionary\n","baseline_model_val_dict = baseline_model_val.history\n","\n","# Print the keys\n","print(baseline_model_val_dict.keys())"]},{"cell_type":"markdown","metadata":{},"source":["Evaluate this model on the training data: "]},{"cell_type":"code","execution_count":78,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["235/235 [==============================] - 0s 609us/step - loss: 1.9278 - acc: 0.1884\n","----------\n","Training Loss: 1.93 \n","Training Accuracy: 0.188\n"]}],"source":["results_train = baseline_model.evaluate(X_train_tokens, y_train_lb)\n","print('----------')\n","print(f'Training Loss: {results_train[0]:.3} \\nTraining Accuracy: {results_train[1]:.3}')"]},{"cell_type":"markdown","metadata":{},"source":["Evaluate this model on the test data: "]},{"cell_type":"code","execution_count":79,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":[" 1/47 [..............................] - ETA: 0s - loss: 1.9620 - acc: 0.0938"]},{"name":"stdout","output_type":"stream","text":["47/47 [==============================] - 0s 782us/step - loss: 1.9275 - acc: 0.1940\n","----------\n","Test Loss: 1.93 \n","Test Accuracy: 0.194\n"]}],"source":["results_test = baseline_model.evaluate(X_test_tokens, y_test_lb)\n","print('----------')\n","print(f'Test Loss: {results_test[0]:.3} \\nTest Accuracy: {results_test[1]:.3}')"]},{"cell_type":"markdown","metadata":{},"source":["### Plot the Results \n","\n","Plot the loss versus the number of epochs. Be sure to include the training and the validation loss in the same plot. "]},{"cell_type":"code","execution_count":80,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["# Loss vs number of epochs with train and validation sets\n","plt.plot(baseline_model_val_dict['loss'], label='Training')\n","plt.plot(baseline_model_val_dict['val_loss'], label='Validation')\n","plt.title('Loss by Epoch')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.legend();"]},{"cell_type":"markdown","metadata":{},"source":["Create a second plot comparing training and validation accuracy to the number of epochs. "]},{"cell_type":"code","execution_count":81,"metadata":{},"outputs":[{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAko0lEQVR4nO3de5QV1Zn38e8v3cpVFAFFaZA2QQmKArbooEYMZgaNAeNlhOgExoy3xKAYVMxFTSZZK+PwTjK+0Tgkok5iJGrUEF9vkYkxiUZpQQ2oRNQWG1ABL5CRW+vz/lHVeGhON6egi3OQ32ets6jau2rXUw19HvbedVFEYGZmVqqPlTsAMzPbsThxmJlZJk4cZmaWiROHmZll4sRhZmaZOHGYmVkmThxmFUDSSEmN5Y5ja0l6RNK/lDsO2z6cOGyHkH4xvS2pQ7ljqXSSbpa0XtLfCj7PlDsu++hw4rCKJ6k/cAwQwJjtfOzq7Xm8dnRNRHQt+Bxa7oDso8OJw3YEXwT+DNwMTCiskNRX0l2SlktaKelHBXXnSHpe0mpJz0kalpaHpE8UbHezpO+myyMlNUq6XNLrwE2Suku6Nz3G2+lyTcH+e0q6SdLStP6etHy+pM8VbLeLpBWShrR2opK+nm7TIOnMtOxwSW8UJjFJp0p6OusPUlL/9PzPTeNdJulrBfUdJP0wrVuaLncoqB8r6WlJqyS9JGl0QfP7SfpT+vN+SFLPrPHZjsGJw3YEXwRuTT//IGlvAElVwL3Aq0B/oA8wM607Hbg63bcbSU9lZYnH6w3sCewHnEvye3JTut4PWAP8qGD7nwGdgYOAvYAfpOX/DZxVsN2JwLKIeLqN4/ZMz2MCMF3SgRExJ439MwXbnpUed2sdBwwA/h6YKun4tPwbwJHAEOBQYDjwTQBJw9NzuhTYA/gU0FDQ5heAfyb5GewKTNmG+KySRYQ//lTsBzga2AD0TNdfACany38HLAeqi+z3IHBRK20G8ImC9ZuB76bLI4H1QMc2YhoCvJ0u7wN8AHQvst2+wGqgW7p+J3BZK22OBJqALgVltwPfSpcvB25Nl/cE3gP2aaWtm4G1wDsFn1vSuv7p+Q8s2P4a4MZ0+SXgxIK6fwAa0uX/An7QyjEfAb5ZsP5l4IFy//vxJ5+PexxW6SYAD0XEinT9F3w4XNUXeDUimors15fkS3BrLI+Itc0rkjpL+i9Jr0paBTwK7JH2ePoCb0XE2y0biYilwJ+AUyXtAZxA0mtqzdsR8b8F66+SJB+AnwOfk9QV+EfgDxGxrI22pkXEHgWfCS3qX2vlOPum68XqtvQzfb1g+T2gaxvb2g5sR534s52ApE4kX5JV6XwDQAeSL+1DSb78+kmqLpI8XgM+3krT75EMLTXrDRReCtvykdFfAw4EjoiI19M5inmA0uPsKWmPiHinyLFuAf6F5Hft8YhY0tr5At0ldSlIHv2A+QARsUTS48DngX8CftxGO6XoS9J7az7O0nR5KcmQ3IIidW39TG0n4h6HVbKTgfeBQSTDQ0OATwJ/IJm7eBJYBnxfUhdJHSUdle77U2CKpMOU+ISk/dK6p4EvSKpKJ3eP3UIcu5HMa7wjaU/gquaK9H/99wPXp5Pou0j6VMG+9wDDgItI5ge25NuSdpV0DHAScEdB3X8DlwGDgbtLaKst30p7UgeRzEv8Mi2/DfimpF7p5PaVJL0dgBuBf5Y0StLHJPWRNHAb47AdkBOHVbIJwE0RsTgiXm/+kExMn0nyP/7PAZ8AFpP0Gs4AiIg7gO+RDG2tJvkC3zNt96J0v3fSdu7ZQhw/BDoBK0iu7nqgRf0/kczDvAC8CVzcXBERa4BfAbXAXVs4zuvA2yT/w78VOD8iXiiov5ukN3B3iyGtYi5rcR/Hihb1vwcWAbNJhrUeSsu/C9QDzwJ/AeamZUTEkyRJ5gfAu2kb+2E7HUX4RU5meZJ0JXBARJy1xY233NZLwHkR8fBW7t8feAXYpZW5IbMt8hyHWY7Soa0vkfRKtrWtU0nmX/5nW9sy2xYeqjLLiaRzSCaU74+IR7exrUdIJsS/EhEftEN4ZlvNQ1VmZpaJexxmZpbJTjHH0bNnz+jfv3+5wzAz26E89dRTKyKiV8vynSJx9O/fn/r6+nKHYWa2Q5H0arFyD1WZmVkmThxmZpaJE4eZmWXixGFmZpk4cZiZWSZOHGZmlokTh5mZZbJT3MexrV5d+b/cNXcJfjyLme1oPj+shtqeXdq1TSeOEsz44yvc8virSOWOxMwsm2H7dXfiKIfX3l7DoH26cd9Fx5Q7FDOzsvMcRwka336PPt07lTsMM7OKkGvikDRa0kJJiyRNLVI/UNLjktZJmtKibrKkBZLmS7pNUse0fIikP0t6WlK9pOF5nkNE0Pj2GmqcOMzMgBwTh6Qq4DrgBGAQMF7SoBabvQVMAqa12LdPWl4XEQcDVcC4tPoa4NsRMQS4Ml3PzdvvbeC99e9T071znocxM9th5NnjGA4sioiXI2I9MBMYW7hBRLwZEXOADUX2rwY6SaoGOgNLm3cDuqXLuxeU52LJ22sA3OMwM0vlOTneh+S1mc0agSNK2TEilkiaBiwG1gAPRcRDafXFwINp/ceAEcXakHQucC5Av379tib+JOi33wOgzx5OHGZmkG+Po9jFqyXdCCGpO0nvpBbYF+gi6ay0+gJgckT0BSYDNxZrIyKmR0RdRNT16rXZe0hK1pj2OPp6qMrMDMg3cTQCfQvWayh9WOl44JWIWB4RG4C7+LBnMSFdB7iDZEgsN0veWcNuHarp1slXLpuZQb6JYw4wQFKtpF1JJrdnlbjvYuBISZ0lCRgFPJ/WLQWOTZc/DbzYjjFvpvlSXPnuPzMzIMc5johoknQh8CDJVVEzImKBpPPT+hsk9QbqSSa7P5B0MTAoIp6QdCcwF2gC5gHT06bPAf4znTRfSzqPkRdfimtmtqlcx18i4j7gvhZlNxQsv04yhFVs36uAq4qU/xE4rH0jLa75Ho4j9++xPQ5nZrZD8J3jbVi1pom/rWtyj8PMrIATRxteSy/FdeIwM/uQE0cbmi/F7bOHL8U1M2vmxNGGJe/4rnEzs5acONrQ+PZ7dNm1ij0671LuUMzMKobvamvDqIF707d7Z9/DYWZWwImjDUcP6MnRA3qWOwwzs4rioSozM8vEicPMzDJx4jAzs0ycOMzMLBMnDjMzy8SJw8zMMnHiMDOzTJw4zMwsEycOMzPLxInDzMwyceIwM7NMck0ckkZLWihpkaSpReoHSnpc0jpJU1rUTZa0QNJ8SbdJ6lhQ99W03QWSrsnzHMzMbFO5JQ5JVcB1wAnAIGC8pEEtNnsLmARMa7Fvn7S8LiIOBqqAcWndccBY4JCIOKjlvmZmlq88exzDgUUR8XJErAdmknzhbxQRb0bEHGBDkf2rgU6SqoHOwNK0/ALg+xGxrrmNvE7AzMw2l2fi6AO8VrDemJZtUUQsIelJLAaWAe9GxENp9QHAMZKekPR7SYcXa0PSuZLqJdUvX758q0/CzMw2lWfiKPb2oyhpR6k7Se+kFtgX6CLprLS6GugOHAlcCtyuIm9aiojpEVEXEXW9evXamvjNzKyIPBNHI9C3YL2GD4ebtuR44JWIWB4RG4C7gBEF7d4ViSeBDwC/bcnMbDvJM3HMAQZIqpW0K8nk9qwS910MHCmpc9qbGAU8n9bdA3waQNIBwK7AivYM3MzMWpfbq2MjoknShcCDJFdFzYiIBZLOT+tvkNQbqAe6AR9IuhgYFBFPSLoTmAs0AfOA6WnTM4AZkuYD64EJEVHSEJiZmW077QzfuXV1dVFfX1/uMMzMdiiSnoqIupblvnPczMwyceIwM7NMnDjMzCwTJw4zM8vEicPMzDJx4jAzs0ycOMzMLBMnDjMzy8SJw8zMMnHiMDOzTJw4zMwsEycOMzPLxInDzMwyceIwM7NMnDjMzCwTJw4zM8vEicPMzDJx4jAzs0xyTRySRktaKGmRpKlF6gdKelzSOklTWtRNlrRA0nxJt0nq2KJ+iqSQ1DPPczAzs03lljgkVQHXAScAg4Dxkga12OwtYBIwrcW+fdLyuog4GKgCxhXU9wU+AyzOK34zMysuzx7HcGBRRLwcEeuBmcDYwg0i4s2ImANsKLJ/NdBJUjXQGVhaUPcD4DIgconczMxalWfi6AO8VrDemJZtUUQsIemFLAaWAe9GxEMAksYASyLimfYN18zMSpFn4lCRspJ6CJK6k/ROaoF9gS6SzpLUGfgGcGUJbZwrqV5S/fLlyzOEbWZmbckzcTQCfQvWa9h0uKktxwOvRMTyiNgA3AWMAD5OkkyekdSQtjlXUu+WDUTE9Iioi4i6Xr16bcNpmJlZoeoc254DDJBUCywhmdz+Qon7LgaOTHsYa4BRQH1E/AXYq3mjNHnURcSK9gzczMxal1viiIgmSRcCD5JcFTUjIhZIOj+tvyHtKdQD3YAPJF0MDIqIJyTdCcwFmoB5wPS8YjUzs9Ip4qN/YVJdXV3U19eXOwwzsx2KpKcioq5lue8cNzOzTJw4zMwsEycOMzPLxInDzMwyceIwM7NMnDjMzCwTJw4zM8vEicPMzDJx4jAzs0ycOMzMLBMnDjMzy8SJw8zMMnHiMDOzTJw4zMwsEycOMzPLxInDzMwyceIwM7NM8nznuJlZu9uwYQONjY2sXbu23KF8ZHTs2JGamhp22WWXkrZ34jCzHUpjYyO77bYb/fv3R1K5w9nhRQQrV66ksbGR2trakvbJdahK0mhJCyUtkjS1SP1ASY9LWidpSou6yZIWSJov6TZJHdPyf5f0gqRnJd0taY88z8HMKsvatWvp0aOHk0Y7kUSPHj0y9eBySxySqoDrgBOAQcB4SYNabPYWMAmY1mLfPml5XUQcDFQB49Lq3wIHR8QhwF+BK/I6BzOrTE4a7SvrzzPPHsdwYFFEvBwR64GZwNjCDSLizYiYA2wosn810ElSNdAZWJru81BENKXb/BmoyesEzMxaWrlyJUOGDGHIkCH07t2bPn36bFxfv359m/vW19czadKkLR5jxIgR7RVuLvKc4+gDvFaw3ggcUcqOEbFE0jRgMbAGeCgiHiqy6dnAL4u1Ielc4FyAfv36ZQjbzKx1PXr04Omnnwbg6quvpmvXrkyZ8uFIe1NTE9XVxb9a6+rqqKur2+IxHnvssXaJNS959jiK9X2ipB2l7iS9k1pgX6CLpLNabPMNoAm4tVgbETE9Iuoioq5Xr16ZAjczy2LixIlccsklHHfccVx++eU8+eSTjBgxgqFDhzJixAgWLlwIwCOPPMJJJ50EJEnn7LPPZuTIkey///5ce+21G9vr2rXrxu1HjhzJaaedxsCBAznzzDOJSL5G77vvPgYOHMjRRx/NpEmTNra7PeTZ42gE+has15AON5XgeOCViFgOIOkuYATw83R9AnASMCqaf4pmttP59m8W8NzSVe3a5qB9u3HV5w7KvN9f//pXHn74Yaqqqli1ahWPPvoo1dXVPPzww3z961/nV7/61Wb7vPDCC/zud79j9erVHHjggVxwwQWbXRI7b948FixYwL777stRRx3Fn/70J+rq6jjvvPN49NFHqa2tZfz48Vt9vlujpMQhqQuwJiI+kHQAMBC4PyKKzU00mwMMkFQLLCGZ3P5CiXEtBo6U1JlkqGoUUJ/GMhq4HDg2It4rsT0zs1ydfvrpVFVVAfDuu+8yYcIEXnzxRSSxYUPxr8rPfvazdOjQgQ4dOrDXXnvxxhtvUFOz6bTt8OHDN5YNGTKEhoYGunbtyv7777/x8tnx48czffr0HM9uU6X2OB4FjkmHkGaTfImfAZzZ2g4R0STpQuBBkquiZkTEAknnp/U3SOqdttUN+EDSxcCgiHhC0p3AXJLhqHlA80/lR0AH4LfplQB/jojzM5yzmX1EbE3PIC9dunTZuPytb32L4447jrvvvpuGhgZGjhxZdJ8OHTpsXK6qqqKpqamkbco90FJq4lBEvCfpS8D/jYhrJM3b0k4RcR9wX4uyGwqWX6eVq6Ii4irgqiLlnygxZjOzsnj33Xfp06cPADfffHO7tz9w4EBefvllGhoa6N+/P7/8ZdFrhHJT6uS4JP0dSQ/j/6VlvuvczKyIyy67jCuuuIKjjjqK999/v93b79SpE9dffz2jR4/m6KOPZu+992b33Xdv9+O0RqV0eSQdC3wN+FNE/Juk/YGLI2LLFyRXgLq6uqivry93GGbWDp5//nk++clPljuMsvvb3/5G165diQi+8pWvMGDAACZPnrzV7RX7uUp6KiI2u364pF5DRPwe+H3a0MeAFTtK0jAz+yj6yU9+wi233ML69esZOnQo55133nY7dqlXVf0COB94H3gK2F3Sf0TEv+cZnJmZFTd58uRt6mFsi1LnOAZFxCrgZJLJ7n7AP+UVlJmZVa5SE8cuknYhSRy/Tu/f8I13ZmY7oVITx38BDUAX4FFJ+wHte7ummZntEEqdHL8WuLag6FVJx+UTkpmZVbKSehySdpf0H5Lq08//Iel9mJntVEaOHMmDDz64SdkPf/hDvvzlL7e6ffPtACeeeCLvvPPOZttcffXVTJs2bbPyQvfccw/PPffcxvUrr7yShx9+OGP07aPUoaoZwGrgH9PPKuCmvIIyM6tU48ePZ+bMmZuUzZw5s6QHDd53333sscceW3XclonjO9/5Dscff/xWtbWtSk0cH4+Iq9KXMr0cEd8G9s8zMDOzSnTaaadx7733sm7dOgAaGhpYunQpv/jFL6irq+Oggw7iqqs2e1oSAP3792fFihUAfO973+PAAw/k+OOP3/jYdUjuzzj88MM59NBDOfXUU3nvvfd47LHHmDVrFpdeeilDhgzhpZdeYuLEidx5550AzJ49m6FDhzJ48GDOPvvsjbH179+fq666imHDhjF48GBeeOGFdvkZlPrYkDWSjo6IPwJIOorkqbVmZuVz/1R4/S/t22bvwXDC91ut7tGjB8OHD+eBBx5g7NixzJw5kzPOOIMrrriCPffck/fff59Ro0bx7LPPcsghhxRt46mnnmLmzJnMmzePpqYmhg0bxmGHHQbAKaecwjnnnAPAN7/5TW688Ua++tWvMmbMGE466SROO+20Tdpau3YtEydOZPbs2RxwwAF88Ytf5Mc//jEXX3wxAD179mTu3Llcf/31TJs2jZ/+9Kfb/CMqtcdxPnCdpAZJDSRPqN1+tymamVWQwuGq5mGq22+/nWHDhjF06FAWLFiwybBSS3/4wx/4/Oc/T+fOnenWrRtjxozZWDd//nyOOeYYBg8ezK233sqCBQvajGXhwoXU1tZywAEHADBhwgQeffTRjfWnnHIKAIcddhgNDQ1be8qbKPWqqmeAQyV1S9dXpY9Af7ZdojAz2xpt9AzydPLJJ3PJJZcwd+5c1qxZQ/fu3Zk2bRpz5syhe/fuTJw4kbVr17bZRvpaiM1MnDiRe+65h0MPPZSbb76ZRx55pM12tvS8webHsrf22PatkenVsRGxKr2DHOCSdonAzGwH07VrV0aOHMnZZ5/N+PHjWbVqFV26dGH33XfnjTfe4P77729z/0996lPcfffdrFmzhtWrV/Ob3/xmY93q1avZZ5992LBhA7fe+uGbsXfbbTdWr169WVsDBw6koaGBRYsWAfCzn/2MY489tp3OtLhteTR68XRpZrYTGD9+PKeccgozZ85k4MCBDB06lIMOOoj999+fo446qs19hw0bxhlnnMGQIUPYb7/9OOaYYzbW/eu//itHHHEE++23H4MHD96YLMaNG8c555zDtddeu3FSHKBjx47cdNNNnH766TQ1NXH44Ydz/vn5vtuupMeqF91RWhwR/do5nlz4sepmHx1+rHo+2u2x6pJWU/yZVAI6bUuQZma2Y2pzjiMidouIbkU+u0XEFoe5JI2WtFDSIklTi9QPlPS4pHWSprSomyxpgaT5km6T1DEt31PSbyW9mP7ZPetJm5nZ1ss0OZ6FpCrgOuAEYBAwXtKgFpu9BUwCprXYt09aXhcRBwNVwLi0eiowOyIGALPTdTMz205ySxzAcGBReqf5emAmMLZwg4h4MyLmABuK7F8NdJJUDXQGlqblY4Fb0uVbSB71bmY7ka2dm7Xisv4880wcfYDXCtYb07ItioglJL2QxcAy4N2IeCit3jsilqXbLQP2areIzazidezYkZUrVzp5tJOIYOXKlXTs2LHkfbblctwtKXa5bkl/0+m8xVigFngHuEPSWRHx85IPLp0LnAvQr98OcfGXmZWgpqaGxsZGli9fXu5QPjI6duxITU1NydvnmTgagb4F6zV8ONy0JccDr0TEcgBJdwEjgJ8Db0jaJyKWSdoHeLNYAxExHZgOyeW4W3cKZlZpdtllF2pra8sdxk4tz6GqOcAASbWSdiWZ3J5V4r6LgSMldVZyX/4o4Pm0bhYwIV2eAPy6HWM2M7MtyK3HERFNki4EHiS5KmpGRCyQdH5af4Ok3kA90A34IH3+1aCIeELSncBcoAmYR9p7AL4P3C7pSyQJ5vS8zsHMzDa31XeO70h857iZWXat3Tme51CVmZl9BDlxmJlZJk4cZmaWiROHmZll4sRhZmaZOHGYmVkmThxmZpaJE4eZmWXixGFmZpk4cZiZWSZOHGZmlokTh5mZZeLEYWZmmThxmJlZJk4cZmaWiROHmZll4sRhZmaZOHGYmVkmThxmZpZJrolD0mhJCyUtkjS1SP1ASY9LWidpSkH5gZKeLvisknRxWjdE0p/T8npJw/M8BzMz21R1Xg1LqgKuAz4DNAJzJM2KiOcKNnsLmAScXLhvRCwEhhS0swS4O62+Bvh2RNwv6cR0fWRe52FmZpvKs8cxHFgUES9HxHpgJjC2cIOIeDMi5gAb2mhnFPBSRLzavBvQLV3eHVjavmGbmVlbcutxAH2A1wrWG4EjtqKdccBtBesXAw9KmkaS+EYU20nSucC5AP369duKw5qZWTF59jhUpCwyNSDtCowB7igovgCYHBF9gcnAjcX2jYjpEVEXEXW9evXKclgzM2tDnomjEehbsF5D9mGlE4C5EfFGQdkE4K50+Q6SITEzM9tO8kwcc4ABkmrTnsM4YFbGNsaz6TAVJMnn2HT508CL2xSlmZllktscR0Q0SboQeBCoAmZExAJJ56f1N0jqDdSTTHZ/kF5yOygiVknqTHJF1nktmj4H+E9J1cBa0nkMMzPbPhSRadphh1RXVxf19fXlDsPMbIci6amIqGtZ7jvHzcwsEycOMzPLxInDzMwyceIwM7NMnDjMzCwTJw4zM8vEicPMzDJx4jAzs0ycOMzMLBMnDjMzy8SJw8zMMnHiMDOzTJw4zMwsEycOMzPLxInDzMwyceIwM7NMnDjMzCwTJw4zM8sk18QhabSkhZIWSZpapH6gpMclrZM0paD8QElPF3xWpe8jb67/atruAknX5HkOZma2qeq8GpZUBVwHfAZoBOZImhURzxVs9hYwCTi5cN+IWAgMKWhnCXB3un4cMBY4JCLWSdorr3MwM7PN5dnjGA4sioiXI2I9MJPkC3+jiHgzIuYAG9poZxTwUkS8mq5fAHw/ItY1t9H+oZuZWWvyTBx9gNcK1hvTsqzGAbcVrB8AHCPpCUm/l3R4sZ0knSupXlL98uXLt+KwZmZWTJ6JQ0XKIlMD0q7AGOCOguJqoDtwJHApcLukzY4VEdMjoi4i6nr16pXlsGZm1oY8E0cj0LdgvQZYmrGNE4C5EfFGi3bvisSTwAdAz22K1MzMSpZn4pgDDJBUm/YcxgGzMrYxnk2HqQDuAT4NIOkAYFdgxbaFamZmpcrtqqqIaJJ0IfAgUAXMiIgFks5P62+Q1BuoB7oBH6SX3A6KiFWSOpNckXVei6ZnADMkzQfWAxMiItMQmJmZbT3tDN+5dXV1UV9fX+4wzMx2KJKeioi6luW+c9zMzDJx4jAzs0ycOMzMLBMnDjMzy8SJw8zMMnHiMDOzTJw4zMwsEycOMzPLxInDzMwyceIwM7NMnDjMzCwTJw4zM8vEicPMzDJx4jAzs0ycOMzMLBMnDjMzy8SJw8zMMnHiMDOzTJw4zMwsk1wTh6TRkhZKWiRpapH6gZIel7RO0pSC8gMlPV3wWSXp4hb7TpEUknrmeQ5mZrap6rwallQFXAd8BmgE5kiaFRHPFWz2FjAJOLlw34hYCAwpaGcJcHdB233TdhfnFb+ZmRWXW+IAhgOLIuJlAEkzgbHAxsQREW8Cb0r6bBvtjAJeiohXC8p+AFwG/Lrdoy50/1R4/S+5HsLMLFe9B8MJ32/XJvMcquoDvFaw3piWZTUOuK15RdIYYElEPNPWTpLOlVQvqX758uVbcVgzMysmzx6HipRFpgakXYExwBXpemfgG8Dfb2nfiJgOTAeoq6vLdNyN2jlLm5l9FOTZ42gE+has1wBLM7ZxAjA3It5I1z8O1ALPSGpI25wrqfc2xmpmZiXKs8cxBxggqZZkcnsc8IWMbYynYJgqIv4C7NW8niaPuohYsc3RmplZSXJLHBHRJOlC4EGgCpgREQsknZ/W35D2FOqBbsAH6SW3gyJiVTos9RngvLxiNDOz7PLscRAR9wH3tSi7oWD5dZLhpmL7vgf02EL7/bc9SjMzy8J3jpuZWSZOHGZmlokTh5mZZeLEYWZmmShi6+6N25FIWg68usUNi+sJVPrlvo6xfTjGbVfp8YFjzGK/iOjVsnCnSBzbQlJ9RNSVO462OMb24Ri3XaXHB46xPXioyszMMnHiMDOzTJw4tmx6uQMogWNsH45x21V6fOAYt5nnOMzMLBP3OMzMLBMnDjMzy8SJow2SRktaKGmRpKkVEE9fSb+T9LykBZIuSsv3lPRbSS+mf3avgFirJM2TdG8lxihpD0l3Snoh/Xn+XQXGODn9e54v6TZJHcsdo6QZkt6UNL+grNWYJF2R/v4slPQPZYzx39O/62cl3S1pj0qLsaBuiqSQ1LOcMbbFiaMVkqqA60heJjUIGC9pUHmjogn4WkR8EjgS+Eoa01RgdkQMAGan6+V2EfB8wXqlxfifwAMRMRA4lCTWiolRUh9gEsn7Zg4meTXBuAqI8WZgdIuyojGl/zbHAQel+1yf/l6VI8bfAgdHxCHAX/nwraKVFCOS+pK8TmJxQVm5YmyVE0frhgOLIuLliFgPzATGljOgiFgWEXPT5dUkX3Z90rhuSTe7BTi5LAGmJNUAnwV+WlBcMTFK6gZ8CrgRICLWR8Q7VFCMqWqgk6RqoDPJGzTLGmNEPAq81aK4tZjGAjMjYl1EvAIsIvm92u4xRsRDEdGUrv6ZD1/nUDExpn4AXMamr9kuS4xtceJoXR/gtYL1xrSsIkjqDwwFngD2johlkCQXCt6SWCY/JPnH/0FBWSXFuD+wHLgpHU77qaQulRRjRCwBppH8z3MZ8G5EPFRJMRZoLaZK/R06G7g/Xa6YGCWNAZZExDMtqiomxmZOHK1TkbKKuHZZUlfgV8DFEbGq3PEUknQS8GZEPFXuWNpQDQwDfhwRQ4H/pfxDZ5tI5wnGArXAvkAXSWeVN6rMKu53SNI3SIZ8b20uKrLZdo8xfePpN4Ari1UXKSvrz9GJo3WNQN+C9RqSoYKykrQLSdK4NSLuSovfkLRPWr8P8Ga54gOOAsak74OfCXxa0s+prBgbgcaIeCJdv5MkkVRSjMcDr0TE8ojYANwFjKiwGJu1FlNF/Q5JmgCcBJwZH97AVikxfpzkPwnPpL87NcBcJa/XrpQYN3LiaN0cYICkWkm7kkxOzSpnQJJEMi7/fET8R0HVLGBCujwB+PX2jq1ZRFwRETXpa33HAf8TEWdRWTG+Drwm6cC0aBTwHBUUI8kQ1ZGSOqd/76NI5rQqKcZmrcU0CxgnqYOkWmAA8GQZ4kPSaOByYEz6WupmFRFjRPwlIvaKiP7p704jMCz9t1oRMW4iIvxp5QOcSHIFxkvANyognqNJuqjPAk+nnxNJ3s0+G3gx/XPPcseaxjsSuDddrqgYgSFAffqzvAfoXoExfht4AZgP/AzoUO4YgdtI5lw2kHy5famtmEiGX14CFgInlDHGRSTzBM2/NzdUWowt6huAnuWMsa2PHzliZmaZeKjKzMwyceIwM7NMnDjMzCwTJw4zM8vEicPMzDJx4jBrB5Lel/R0wafd7kSX1L/YU1TNyqW63AGYfUSsiYgh5Q7CbHtwj8MsR5IaJP2bpCfTzyfS8v0kzU7fDzFbUr+0fO/0fRHPpJ8RaVNVkn6Svp/jIUmdynZSttNz4jBrH51aDFWdUVC3KiKGAz8ieXIw6fJ/R/J+iFuBa9Pya4HfR8ShJM/PWpCWDwCui4iDgHeAU3M9G7M2+M5xs3Yg6W8R0bVIeQPw6Yh4OX1A5esR0UPSCmCfiNiQli+LiJ6SlgM1EbGuoI3+wG8jeVESki4HdomI726HUzPbjHscZvmLVpZb26aYdQXL7+P5SSsjJw6z/J1R8Ofj6fJjJE8PBjgT+GO6PBu4ADa+t73b9grSrFT+X4tZ++gk6emC9QciovmS3A6SniD5j9r4tGwSMEPSpSRvI/zntPwiYLqkL5H0LC4geYqqWcXwHIdZjtI5jrqIWFHuWMzai4eqzMwsE/c4zMwsE/c4zMwsEycOMzPLxInDzMwyceIwM7NMnDjMzCyT/w+UpkcvRPU07wAAAABJRU5ErkJggg==","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["# Accuracy vs number of epochs with train and validation sets\n","plt.plot(baseline_model_val_dict['acc'], label='Training')\n","plt.plot(baseline_model_val_dict['val_acc'], label='Validation')\n","plt.title('Accuracy by Epoch')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.legend();"]},{"cell_type":"markdown","metadata":{},"source":["Did you notice an interesting pattern here? Although the training accuracy keeps increasing when going through more epochs, and the training loss keeps decreasing, the validation accuracy and loss don't necessarily do the same. After a certain point, validation accuracy keeps swinging, which means that you're probably **overfitting** the model to the training data when you train for many epochs past a certain dropoff point. Let's tackle this now. You will now specify an early stopping point when training your model. \n","\n","\n","## Early Stopping\n","\n","Overfitting neural networks is something you **_want_** to avoid at all costs. However, it's not possible to know in advance how many *epochs* you need to train your model on, and running the model multiple times with varying number of *epochs* maybe helpful, but is a time-consuming process. \n","\n","We've defined a model with the same architecture as above. This time specify an early stopping point when training the model. "]},{"cell_type":"code","execution_count":82,"metadata":{},"outputs":[],"source":["random.seed(123)\n","model_2 = models.Sequential()\n","model_2.add(layers.Dense(50, activation='relu', input_shape=(2000,)))\n","model_2.add(layers.Dense(25, activation='relu'))\n","model_2.add(layers.Dense(7, activation='softmax'))\n","\n","model_2.compile(optimizer='SGD', \n","                loss='categorical_crossentropy', \n","                metrics=['acc'])"]},{"cell_type":"markdown","metadata":{},"source":["- Import `EarlyStopping` and `ModelCheckpoint` from `keras.callbacks` \n","- Define a list, `early_stopping`: \n","  - Monitor `'val_loss'` and continue training for 10 epochs before stopping \n","  - Save the best model while monitoring `'val_loss'` \n"," \n","> If you need help, consult [documentation](https://keras.io/callbacks/).   "]},{"cell_type":"code","execution_count":83,"metadata":{},"outputs":[],"source":["# Import EarlyStopping and ModelCheckpoint\n","from keras.callbacks import EarlyStopping, ModelCheckpoint\n","\n","# Define the callbacks\n","early_stopping = [EarlyStopping(monitor='val_loss', patience=10),\n","                  ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True)]"]},{"cell_type":"markdown","metadata":{},"source":["Train `model_2`. Make sure you set the `callbacks` argument to `early_stopping`. "]},{"cell_type":"code","execution_count":84,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/150\n","30/30 [==============================] - 0s 7ms/step - loss: 1.9452 - acc: 0.1864 - val_loss: 1.9446 - val_acc: 0.1740\n","Epoch 2/150\n","30/30 [==============================] - 0s 4ms/step - loss: 1.9438 - acc: 0.1884 - val_loss: 1.9435 - val_acc: 0.1740\n","Epoch 3/150\n","30/30 [==============================] - 0s 4ms/step - loss: 1.9425 - acc: 0.1884 - val_loss: 1.9424 - val_acc: 0.1740\n","Epoch 4/150\n","30/30 [==============================] - 0s 4ms/step - loss: 1.9413 - acc: 0.1884 - val_loss: 1.9414 - val_acc: 0.1740\n","Epoch 5/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9403 - acc: 0.1884 - val_loss: 1.9406 - val_acc: 0.1740\n","Epoch 6/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9393 - acc: 0.1884 - val_loss: 1.9398 - val_acc: 0.1740\n","Epoch 7/150\n","30/30 [==============================] - 0s 4ms/step - loss: 1.9384 - acc: 0.1884 - val_loss: 1.9391 - val_acc: 0.1740\n","Epoch 8/150\n","30/30 [==============================] - 0s 4ms/step - loss: 1.9375 - acc: 0.1884 - val_loss: 1.9384 - val_acc: 0.1740\n","Epoch 9/150\n","30/30 [==============================] - 0s 4ms/step - loss: 1.9367 - acc: 0.1884 - val_loss: 1.9378 - val_acc: 0.1740\n","Epoch 10/150\n","30/30 [==============================] - 0s 4ms/step - loss: 1.9360 - acc: 0.1884 - val_loss: 1.9373 - val_acc: 0.1740\n","Epoch 11/150\n","30/30 [==============================] - 0s 4ms/step - loss: 1.9354 - acc: 0.1884 - val_loss: 1.9367 - val_acc: 0.1740\n","Epoch 12/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9348 - acc: 0.1884 - val_loss: 1.9363 - val_acc: 0.1740\n","Epoch 13/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9342 - acc: 0.1884 - val_loss: 1.9358 - val_acc: 0.1740\n","Epoch 14/150\n","30/30 [==============================] - 0s 4ms/step - loss: 1.9337 - acc: 0.1884 - val_loss: 1.9355 - val_acc: 0.1740\n","Epoch 15/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9332 - acc: 0.1884 - val_loss: 1.9351 - val_acc: 0.1740\n","Epoch 16/150\n","30/30 [==============================] - 0s 4ms/step - loss: 1.9328 - acc: 0.1884 - val_loss: 1.9348 - val_acc: 0.1740\n","Epoch 17/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9324 - acc: 0.1884 - val_loss: 1.9345 - val_acc: 0.1740\n","Epoch 18/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9321 - acc: 0.1884 - val_loss: 1.9343 - val_acc: 0.1740\n","Epoch 19/150\n","30/30 [==============================] - 0s 4ms/step - loss: 1.9317 - acc: 0.1884 - val_loss: 1.9340 - val_acc: 0.1740\n","Epoch 20/150\n","30/30 [==============================] - 0s 4ms/step - loss: 1.9314 - acc: 0.1884 - val_loss: 1.9338 - val_acc: 0.1740\n","Epoch 21/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9311 - acc: 0.1884 - val_loss: 1.9336 - val_acc: 0.1740\n","Epoch 22/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9309 - acc: 0.1884 - val_loss: 1.9334 - val_acc: 0.1740\n","Epoch 23/150\n","30/30 [==============================] - 0s 4ms/step - loss: 1.9306 - acc: 0.1884 - val_loss: 1.9333 - val_acc: 0.1740\n","Epoch 24/150\n","30/30 [==============================] - 0s 4ms/step - loss: 1.9304 - acc: 0.1884 - val_loss: 1.9331 - val_acc: 0.1740\n","Epoch 25/150\n","30/30 [==============================] - 0s 4ms/step - loss: 1.9302 - acc: 0.1884 - val_loss: 1.9330 - val_acc: 0.1740\n","Epoch 26/150\n","30/30 [==============================] - 0s 4ms/step - loss: 1.9300 - acc: 0.1884 - val_loss: 1.9329 - val_acc: 0.1740\n","Epoch 27/150\n","30/30 [==============================] - 0s 4ms/step - loss: 1.9299 - acc: 0.1884 - val_loss: 1.9327 - val_acc: 0.1740\n","Epoch 28/150\n","30/30 [==============================] - 0s 4ms/step - loss: 1.9297 - acc: 0.1884 - val_loss: 1.9326 - val_acc: 0.1740\n","Epoch 29/150\n","30/30 [==============================] - 0s 4ms/step - loss: 1.9296 - acc: 0.1884 - val_loss: 1.9326 - val_acc: 0.1740\n","Epoch 30/150\n","30/30 [==============================] - 0s 4ms/step - loss: 1.9294 - acc: 0.1884 - val_loss: 1.9325 - val_acc: 0.1740\n","Epoch 31/150\n","30/30 [==============================] - 0s 4ms/step - loss: 1.9293 - acc: 0.1884 - val_loss: 1.9324 - val_acc: 0.1740\n","Epoch 32/150\n","30/30 [==============================] - 0s 4ms/step - loss: 1.9292 - acc: 0.1884 - val_loss: 1.9324 - val_acc: 0.1740\n","Epoch 33/150\n","30/30 [==============================] - 0s 4ms/step - loss: 1.9291 - acc: 0.1884 - val_loss: 1.9323 - val_acc: 0.1740\n","Epoch 34/150\n","30/30 [==============================] - 0s 4ms/step - loss: 1.9290 - acc: 0.1884 - val_loss: 1.9322 - val_acc: 0.1740\n","Epoch 35/150\n","30/30 [==============================] - 0s 4ms/step - loss: 1.9289 - acc: 0.1884 - val_loss: 1.9322 - val_acc: 0.1740\n","Epoch 36/150\n","30/30 [==============================] - 0s 4ms/step - loss: 1.9288 - acc: 0.1884 - val_loss: 1.9322 - val_acc: 0.1740\n","Epoch 37/150\n","30/30 [==============================] - 0s 4ms/step - loss: 1.9288 - acc: 0.1884 - val_loss: 1.9321 - val_acc: 0.1740\n","Epoch 38/150\n","30/30 [==============================] - 0s 4ms/step - loss: 1.9287 - acc: 0.1884 - val_loss: 1.9321 - val_acc: 0.1740\n","Epoch 39/150\n","30/30 [==============================] - 0s 4ms/step - loss: 1.9286 - acc: 0.1884 - val_loss: 1.9321 - val_acc: 0.1740\n","Epoch 40/150\n","30/30 [==============================] - 0s 4ms/step - loss: 1.9286 - acc: 0.1884 - val_loss: 1.9321 - val_acc: 0.1740\n","Epoch 41/150\n","30/30 [==============================] - 0s 4ms/step - loss: 1.9285 - acc: 0.1884 - val_loss: 1.9321 - val_acc: 0.1740\n","Epoch 42/150\n","30/30 [==============================] - 0s 4ms/step - loss: 1.9284 - acc: 0.1884 - val_loss: 1.9320 - val_acc: 0.1740\n","Epoch 43/150\n","30/30 [==============================] - 0s 4ms/step - loss: 1.9284 - acc: 0.1884 - val_loss: 1.9320 - val_acc: 0.1740\n","Epoch 44/150\n","30/30 [==============================] - 0s 4ms/step - loss: 1.9284 - acc: 0.1884 - val_loss: 1.9320 - val_acc: 0.1740\n","Epoch 45/150\n","30/30 [==============================] - 0s 4ms/step - loss: 1.9283 - acc: 0.1884 - val_loss: 1.9320 - val_acc: 0.1740\n","Epoch 46/150\n","30/30 [==============================] - 0s 4ms/step - loss: 1.9283 - acc: 0.1884 - val_loss: 1.9320 - val_acc: 0.1740\n","Epoch 47/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9283 - acc: 0.1884 - val_loss: 1.9320 - val_acc: 0.1740\n","Epoch 48/150\n","30/30 [==============================] - 0s 4ms/step - loss: 1.9282 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 49/150\n","30/30 [==============================] - 0s 4ms/step - loss: 1.9282 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 50/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9282 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 51/150\n","30/30 [==============================] - 0s 4ms/step - loss: 1.9281 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 52/150\n","30/30 [==============================] - 0s 4ms/step - loss: 1.9281 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 53/150\n","30/30 [==============================] - 0s 4ms/step - loss: 1.9281 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 54/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9281 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 55/150\n","30/30 [==============================] - 0s 4ms/step - loss: 1.9281 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 56/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9280 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 57/150\n","30/30 [==============================] - 0s 4ms/step - loss: 1.9280 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 58/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9280 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 59/150\n","30/30 [==============================] - 0s 4ms/step - loss: 1.9280 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 60/150\n","30/30 [==============================] - 0s 4ms/step - loss: 1.9280 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 61/150\n","30/30 [==============================] - 0s 4ms/step - loss: 1.9280 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 62/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9280 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 63/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9280 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 64/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9280 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 65/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9279 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 66/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9279 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 67/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9279 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 68/150\n","30/30 [==============================] - 0s 4ms/step - loss: 1.9279 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 69/150\n","30/30 [==============================] - 0s 4ms/step - loss: 1.9279 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 70/150\n","30/30 [==============================] - 0s 4ms/step - loss: 1.9279 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 71/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9279 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 72/150\n","30/30 [==============================] - 0s 4ms/step - loss: 1.9279 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 73/150\n","30/30 [==============================] - 0s 4ms/step - loss: 1.9279 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 74/150\n","30/30 [==============================] - 0s 4ms/step - loss: 1.9279 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 75/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9279 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 76/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9279 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 77/150\n","30/30 [==============================] - 0s 4ms/step - loss: 1.9279 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 78/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9279 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 79/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9279 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 80/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9279 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 81/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9279 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 82/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9279 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 83/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9279 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 84/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9279 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n"]}],"source":["model_2_val = model_2.fit(X_train_tokens,\n","                          y_train_lb,\n","                          epochs=150,\n","                          callbacks=early_stopping,\n","                          batch_size=256,\n","                          validation_data=(X_val_tokens, y_val_lb))"]},{"cell_type":"markdown","metadata":{},"source":["Load the best (saved) model. "]},{"cell_type":"code","execution_count":85,"metadata":{},"outputs":[],"source":["# Load the best (saved) model\n","from keras.models import load_model\n","\n","saved_model = load_model('best_model.h5')"]},{"cell_type":"markdown","metadata":{},"source":["Now, use this model to to calculate the training and test accuracy: "]},{"cell_type":"code","execution_count":86,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["235/235 [==============================] - 0s 1ms/step - loss: 1.9279 - acc: 0.1884\n","Training Loss: 1.93 \n","Training Accuracy: 0.188\n","----------\n","47/47 [==============================] - 0s 1ms/step - loss: 1.9275 - acc: 0.1940\n","Test Loss: 1.93 \n","Test Accuracy: 0.194\n"]}],"source":["results_train = saved_model.evaluate(X_train_tokens, y_train_lb)\n","print(f'Training Loss: {results_train[0]:.3} \\nTraining Accuracy: {results_train[1]:.3}')\n","\n","print('----------')\n","\n","results_test = saved_model.evaluate(X_test_tokens, y_test_lb)\n","print(f'Test Loss: {results_test[0]:.3} \\nTest Accuracy: {results_test[1]:.3}')"]},{"cell_type":"markdown","metadata":{},"source":["Nicely done! Did you notice that the model didn't train for all 150 epochs? You reduced your training time. \n","\n","Now, take a look at how regularization techniques can further improve your model performance. \n","\n","## L2 Regularization \n","\n","First, take a look at L2 regularization. Keras makes L2 regularization easy. Simply add the `kernel_regularizer=keras.regularizers.l2(lambda_coeff)` parameter to any model layer. The `lambda_coeff` parameter determines the strength of the regularization you wish to perform. \n","\n","- Use 2 hidden layers with 50 units in the first and 25 in the second layer, both with `'relu'` activation functions \n","- Add L2 regularization to both the hidden layers with 0.005 as the `lambda_coeff` "]},{"cell_type":"code","execution_count":87,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/150\n","30/30 [==============================] - 0s 6ms/step - loss: 2.5952 - acc: 0.1872 - val_loss: 2.5925 - val_acc: 0.1740\n","Epoch 2/150\n","30/30 [==============================] - 0s 4ms/step - loss: 2.5899 - acc: 0.1884 - val_loss: 2.5875 - val_acc: 0.1740\n","Epoch 3/150\n","30/30 [==============================] - 0s 4ms/step - loss: 2.5847 - acc: 0.1884 - val_loss: 2.5826 - val_acc: 0.1740\n","Epoch 4/150\n","30/30 [==============================] - 0s 4ms/step - loss: 2.5797 - acc: 0.1884 - val_loss: 2.5778 - val_acc: 0.1740\n","Epoch 5/150\n","30/30 [==============================] - 0s 4ms/step - loss: 2.5748 - acc: 0.1884 - val_loss: 2.5731 - val_acc: 0.1740\n","Epoch 6/150\n","30/30 [==============================] - 0s 4ms/step - loss: 2.5700 - acc: 0.1884 - val_loss: 2.5685 - val_acc: 0.1740\n","Epoch 7/150\n","30/30 [==============================] - 0s 4ms/step - loss: 2.5653 - acc: 0.1884 - val_loss: 2.5640 - val_acc: 0.1740\n","Epoch 8/150\n","30/30 [==============================] - 0s 4ms/step - loss: 2.5607 - acc: 0.1884 - val_loss: 2.5597 - val_acc: 0.1740\n","Epoch 9/150\n","30/30 [==============================] - 0s 5ms/step - loss: 2.5562 - acc: 0.1884 - val_loss: 2.5553 - val_acc: 0.1740\n","Epoch 10/150\n","30/30 [==============================] - 0s 4ms/step - loss: 2.5518 - acc: 0.1884 - val_loss: 2.5511 - val_acc: 0.1740\n","Epoch 11/150\n","30/30 [==============================] - 0s 4ms/step - loss: 2.5475 - acc: 0.1884 - val_loss: 2.5469 - val_acc: 0.1740\n","Epoch 12/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.5432 - acc: 0.1884 - val_loss: 2.5428 - val_acc: 0.1740\n","Epoch 13/150\n","30/30 [==============================] - 0s 4ms/step - loss: 2.5390 - acc: 0.1884 - val_loss: 2.5388 - val_acc: 0.1740\n","Epoch 14/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.5349 - acc: 0.1884 - val_loss: 2.5348 - val_acc: 0.1740\n","Epoch 15/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.5309 - acc: 0.1884 - val_loss: 2.5308 - val_acc: 0.1740\n","Epoch 16/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.5269 - acc: 0.1884 - val_loss: 2.5270 - val_acc: 0.1740\n","Epoch 17/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.5229 - acc: 0.1884 - val_loss: 2.5231 - val_acc: 0.1740\n","Epoch 18/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.5190 - acc: 0.1884 - val_loss: 2.5193 - val_acc: 0.1740\n","Epoch 19/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.5152 - acc: 0.1884 - val_loss: 2.5156 - val_acc: 0.1740\n","Epoch 20/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.5114 - acc: 0.1884 - val_loss: 2.5119 - val_acc: 0.1740\n","Epoch 21/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.5076 - acc: 0.1884 - val_loss: 2.5082 - val_acc: 0.1740\n","Epoch 22/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.5039 - acc: 0.1884 - val_loss: 2.5046 - val_acc: 0.1740\n","Epoch 23/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.5002 - acc: 0.1884 - val_loss: 2.5011 - val_acc: 0.1740\n","Epoch 24/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.4966 - acc: 0.1884 - val_loss: 2.4975 - val_acc: 0.1740\n","Epoch 25/150\n","30/30 [==============================] - 0s 4ms/step - loss: 2.4930 - acc: 0.1884 - val_loss: 2.4940 - val_acc: 0.1740\n","Epoch 26/150\n","30/30 [==============================] - 0s 4ms/step - loss: 2.4895 - acc: 0.1884 - val_loss: 2.4905 - val_acc: 0.1740\n","Epoch 27/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.4859 - acc: 0.1884 - val_loss: 2.4871 - val_acc: 0.1740\n","Epoch 28/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.4825 - acc: 0.1884 - val_loss: 2.4837 - val_acc: 0.1740\n","Epoch 29/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.4790 - acc: 0.1884 - val_loss: 2.4803 - val_acc: 0.1740\n","Epoch 30/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.4756 - acc: 0.1884 - val_loss: 2.4769 - val_acc: 0.1740\n","Epoch 31/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.4722 - acc: 0.1884 - val_loss: 2.4736 - val_acc: 0.1740\n","Epoch 32/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.4688 - acc: 0.1884 - val_loss: 2.4703 - val_acc: 0.1740\n","Epoch 33/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.4655 - acc: 0.1884 - val_loss: 2.4670 - val_acc: 0.1740\n","Epoch 34/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.4622 - acc: 0.1884 - val_loss: 2.4638 - val_acc: 0.1740\n","Epoch 35/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.4589 - acc: 0.1884 - val_loss: 2.4605 - val_acc: 0.1740\n","Epoch 36/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.4557 - acc: 0.1884 - val_loss: 2.4573 - val_acc: 0.1740\n","Epoch 37/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.4524 - acc: 0.1884 - val_loss: 2.4541 - val_acc: 0.1740\n","Epoch 38/150\n","30/30 [==============================] - 0s 4ms/step - loss: 2.4492 - acc: 0.1884 - val_loss: 2.4510 - val_acc: 0.1740\n","Epoch 39/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.4461 - acc: 0.1884 - val_loss: 2.4478 - val_acc: 0.1740\n","Epoch 40/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.4429 - acc: 0.1884 - val_loss: 2.4447 - val_acc: 0.1740\n","Epoch 41/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.4398 - acc: 0.1884 - val_loss: 2.4416 - val_acc: 0.1740\n","Epoch 42/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.4367 - acc: 0.1884 - val_loss: 2.4386 - val_acc: 0.1740\n","Epoch 43/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.4336 - acc: 0.1884 - val_loss: 2.4355 - val_acc: 0.1740\n","Epoch 44/150\n","30/30 [==============================] - 0s 4ms/step - loss: 2.4305 - acc: 0.1884 - val_loss: 2.4325 - val_acc: 0.1740\n","Epoch 45/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.4275 - acc: 0.1884 - val_loss: 2.4295 - val_acc: 0.1740\n","Epoch 46/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.4244 - acc: 0.1884 - val_loss: 2.4265 - val_acc: 0.1740\n","Epoch 47/150\n","30/30 [==============================] - 0s 4ms/step - loss: 2.4214 - acc: 0.1884 - val_loss: 2.4235 - val_acc: 0.1740\n","Epoch 48/150\n","30/30 [==============================] - 0s 4ms/step - loss: 2.4185 - acc: 0.1884 - val_loss: 2.4206 - val_acc: 0.1740\n","Epoch 49/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.4155 - acc: 0.1884 - val_loss: 2.4177 - val_acc: 0.1740\n","Epoch 50/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.4126 - acc: 0.1884 - val_loss: 2.4147 - val_acc: 0.1740\n","Epoch 51/150\n","30/30 [==============================] - 0s 4ms/step - loss: 2.4096 - acc: 0.1884 - val_loss: 2.4119 - val_acc: 0.1740\n","Epoch 52/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.4067 - acc: 0.1884 - val_loss: 2.4090 - val_acc: 0.1740\n","Epoch 53/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.4038 - acc: 0.1884 - val_loss: 2.4061 - val_acc: 0.1740\n","Epoch 54/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.4010 - acc: 0.1884 - val_loss: 2.4033 - val_acc: 0.1740\n","Epoch 55/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.3981 - acc: 0.1884 - val_loss: 2.4005 - val_acc: 0.1740\n","Epoch 56/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.3953 - acc: 0.1884 - val_loss: 2.3977 - val_acc: 0.1740\n","Epoch 57/150\n","30/30 [==============================] - 0s 4ms/step - loss: 2.3925 - acc: 0.1884 - val_loss: 2.3949 - val_acc: 0.1740\n","Epoch 58/150\n","30/30 [==============================] - 0s 4ms/step - loss: 2.3897 - acc: 0.1884 - val_loss: 2.3921 - val_acc: 0.1740\n","Epoch 59/150\n","30/30 [==============================] - 0s 4ms/step - loss: 2.3869 - acc: 0.1884 - val_loss: 2.3893 - val_acc: 0.1740\n","Epoch 60/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.3842 - acc: 0.1884 - val_loss: 2.3866 - val_acc: 0.1740\n","Epoch 61/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.3814 - acc: 0.1884 - val_loss: 2.3839 - val_acc: 0.1740\n","Epoch 62/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.3787 - acc: 0.1884 - val_loss: 2.3812 - val_acc: 0.1740\n","Epoch 63/150\n","30/30 [==============================] - 0s 4ms/step - loss: 2.3760 - acc: 0.1884 - val_loss: 2.3785 - val_acc: 0.1740\n","Epoch 64/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.3733 - acc: 0.1884 - val_loss: 2.3758 - val_acc: 0.1740\n","Epoch 65/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.3706 - acc: 0.1884 - val_loss: 2.3731 - val_acc: 0.1740\n","Epoch 66/150\n","30/30 [==============================] - 0s 4ms/step - loss: 2.3680 - acc: 0.1884 - val_loss: 2.3705 - val_acc: 0.1740\n","Epoch 67/150\n","30/30 [==============================] - 0s 4ms/step - loss: 2.3653 - acc: 0.1884 - val_loss: 2.3679 - val_acc: 0.1740\n","Epoch 68/150\n","30/30 [==============================] - 0s 4ms/step - loss: 2.3627 - acc: 0.1884 - val_loss: 2.3653 - val_acc: 0.1740\n","Epoch 69/150\n","30/30 [==============================] - 0s 4ms/step - loss: 2.3601 - acc: 0.1884 - val_loss: 2.3627 - val_acc: 0.1740\n","Epoch 70/150\n","30/30 [==============================] - 0s 4ms/step - loss: 2.3575 - acc: 0.1884 - val_loss: 2.3602 - val_acc: 0.1740\n","Epoch 71/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.3549 - acc: 0.1884 - val_loss: 2.3576 - val_acc: 0.1740\n","Epoch 72/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.3524 - acc: 0.1884 - val_loss: 2.3550 - val_acc: 0.1740\n","Epoch 73/150\n","30/30 [==============================] - 0s 4ms/step - loss: 2.3498 - acc: 0.1884 - val_loss: 2.3525 - val_acc: 0.1740\n","Epoch 74/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.3473 - acc: 0.1884 - val_loss: 2.3500 - val_acc: 0.1740\n","Epoch 75/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.3448 - acc: 0.1884 - val_loss: 2.3475 - val_acc: 0.1740\n","Epoch 76/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.3423 - acc: 0.1884 - val_loss: 2.3450 - val_acc: 0.1740\n","Epoch 77/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.3398 - acc: 0.1884 - val_loss: 2.3425 - val_acc: 0.1740\n","Epoch 78/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.3373 - acc: 0.1884 - val_loss: 2.3401 - val_acc: 0.1740\n","Epoch 79/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.3349 - acc: 0.1884 - val_loss: 2.3376 - val_acc: 0.1740\n","Epoch 80/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.3325 - acc: 0.1884 - val_loss: 2.3352 - val_acc: 0.1740\n","Epoch 81/150\n","30/30 [==============================] - 0s 4ms/step - loss: 2.3300 - acc: 0.1884 - val_loss: 2.3328 - val_acc: 0.1740\n","Epoch 82/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.3276 - acc: 0.1884 - val_loss: 2.3304 - val_acc: 0.1740\n","Epoch 83/150\n","30/30 [==============================] - 0s 6ms/step - loss: 2.3252 - acc: 0.1884 - val_loss: 2.3280 - val_acc: 0.1740\n","Epoch 84/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.3229 - acc: 0.1884 - val_loss: 2.3257 - val_acc: 0.1740\n","Epoch 85/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.3205 - acc: 0.1884 - val_loss: 2.3233 - val_acc: 0.1740\n","Epoch 86/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.3181 - acc: 0.1884 - val_loss: 2.3210 - val_acc: 0.1740\n","Epoch 87/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.3158 - acc: 0.1884 - val_loss: 2.3187 - val_acc: 0.1740\n","Epoch 88/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.3135 - acc: 0.1884 - val_loss: 2.3163 - val_acc: 0.1740\n","Epoch 89/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.3112 - acc: 0.1884 - val_loss: 2.3140 - val_acc: 0.1740\n","Epoch 90/150\n","30/30 [==============================] - 0s 4ms/step - loss: 2.3089 - acc: 0.1884 - val_loss: 2.3118 - val_acc: 0.1740\n","Epoch 91/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.3066 - acc: 0.1884 - val_loss: 2.3095 - val_acc: 0.1740\n","Epoch 92/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.3043 - acc: 0.1884 - val_loss: 2.3073 - val_acc: 0.1740\n","Epoch 93/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.3021 - acc: 0.1884 - val_loss: 2.3050 - val_acc: 0.1740\n","Epoch 94/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.2998 - acc: 0.1884 - val_loss: 2.3028 - val_acc: 0.1740\n","Epoch 95/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.2976 - acc: 0.1884 - val_loss: 2.3005 - val_acc: 0.1740\n","Epoch 96/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.2954 - acc: 0.1884 - val_loss: 2.2983 - val_acc: 0.1740\n","Epoch 97/150\n","30/30 [==============================] - 0s 4ms/step - loss: 2.2932 - acc: 0.1884 - val_loss: 2.2961 - val_acc: 0.1740\n","Epoch 98/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.2910 - acc: 0.1884 - val_loss: 2.2940 - val_acc: 0.1740\n","Epoch 99/150\n","30/30 [==============================] - 0s 4ms/step - loss: 2.2888 - acc: 0.1884 - val_loss: 2.2918 - val_acc: 0.1740\n","Epoch 100/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.2867 - acc: 0.1884 - val_loss: 2.2896 - val_acc: 0.1740\n","Epoch 101/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.2845 - acc: 0.1884 - val_loss: 2.2875 - val_acc: 0.1740\n","Epoch 102/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.2824 - acc: 0.1884 - val_loss: 2.2854 - val_acc: 0.1740\n","Epoch 103/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.2803 - acc: 0.1884 - val_loss: 2.2833 - val_acc: 0.1740\n","Epoch 104/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.2782 - acc: 0.1884 - val_loss: 2.2812 - val_acc: 0.1740\n","Epoch 105/150\n","30/30 [==============================] - 0s 4ms/step - loss: 2.2761 - acc: 0.1884 - val_loss: 2.2791 - val_acc: 0.1740\n","Epoch 106/150\n","30/30 [==============================] - 0s 4ms/step - loss: 2.2740 - acc: 0.1884 - val_loss: 2.2770 - val_acc: 0.1740\n","Epoch 107/150\n","30/30 [==============================] - 0s 4ms/step - loss: 2.2719 - acc: 0.1884 - val_loss: 2.2749 - val_acc: 0.1740\n","Epoch 108/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.2699 - acc: 0.1884 - val_loss: 2.2729 - val_acc: 0.1740\n","Epoch 109/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.2678 - acc: 0.1884 - val_loss: 2.2708 - val_acc: 0.1740\n","Epoch 110/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.2658 - acc: 0.1884 - val_loss: 2.2688 - val_acc: 0.1740\n","Epoch 111/150\n","30/30 [==============================] - 0s 4ms/step - loss: 2.2637 - acc: 0.1884 - val_loss: 2.2668 - val_acc: 0.1740\n","Epoch 112/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.2617 - acc: 0.1884 - val_loss: 2.2648 - val_acc: 0.1740\n","Epoch 113/150\n","30/30 [==============================] - 0s 4ms/step - loss: 2.2597 - acc: 0.1884 - val_loss: 2.2628 - val_acc: 0.1740\n","Epoch 114/150\n","30/30 [==============================] - 0s 4ms/step - loss: 2.2578 - acc: 0.1884 - val_loss: 2.2608 - val_acc: 0.1740\n","Epoch 115/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.2558 - acc: 0.1884 - val_loss: 2.2588 - val_acc: 0.1740\n","Epoch 116/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.2538 - acc: 0.1884 - val_loss: 2.2569 - val_acc: 0.1740\n","Epoch 117/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.2519 - acc: 0.1884 - val_loss: 2.2549 - val_acc: 0.1740\n","Epoch 118/150\n","30/30 [==============================] - 0s 6ms/step - loss: 2.2499 - acc: 0.1884 - val_loss: 2.2530 - val_acc: 0.1740\n","Epoch 119/150\n","30/30 [==============================] - 0s 4ms/step - loss: 2.2480 - acc: 0.1884 - val_loss: 2.2511 - val_acc: 0.1740\n","Epoch 120/150\n","30/30 [==============================] - 0s 4ms/step - loss: 2.2461 - acc: 0.1884 - val_loss: 2.2492 - val_acc: 0.1740\n","Epoch 121/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.2442 - acc: 0.1884 - val_loss: 2.2473 - val_acc: 0.1740\n","Epoch 122/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.2423 - acc: 0.1884 - val_loss: 2.2454 - val_acc: 0.1740\n","Epoch 123/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.2404 - acc: 0.1884 - val_loss: 2.2435 - val_acc: 0.1740\n","Epoch 124/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.2385 - acc: 0.1884 - val_loss: 2.2417 - val_acc: 0.1740\n","Epoch 125/150\n","30/30 [==============================] - 0s 4ms/step - loss: 2.2367 - acc: 0.1884 - val_loss: 2.2398 - val_acc: 0.1740\n","Epoch 126/150\n","30/30 [==============================] - 0s 4ms/step - loss: 2.2348 - acc: 0.1884 - val_loss: 2.2380 - val_acc: 0.1740\n","Epoch 127/150\n","30/30 [==============================] - 0s 4ms/step - loss: 2.2330 - acc: 0.1884 - val_loss: 2.2362 - val_acc: 0.1740\n","Epoch 128/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.2312 - acc: 0.1884 - val_loss: 2.2343 - val_acc: 0.1740\n","Epoch 129/150\n","30/30 [==============================] - 0s 4ms/step - loss: 2.2294 - acc: 0.1884 - val_loss: 2.2325 - val_acc: 0.1740\n","Epoch 130/150\n","30/30 [==============================] - 0s 4ms/step - loss: 2.2276 - acc: 0.1884 - val_loss: 2.2307 - val_acc: 0.1740\n","Epoch 131/150\n","30/30 [==============================] - 0s 4ms/step - loss: 2.2258 - acc: 0.1884 - val_loss: 2.2289 - val_acc: 0.1740\n","Epoch 132/150\n","30/30 [==============================] - 0s 4ms/step - loss: 2.2240 - acc: 0.1884 - val_loss: 2.2271 - val_acc: 0.1740\n","Epoch 133/150\n","30/30 [==============================] - 0s 4ms/step - loss: 2.2222 - acc: 0.1884 - val_loss: 2.2254 - val_acc: 0.1740\n","Epoch 134/150\n","30/30 [==============================] - 0s 4ms/step - loss: 2.2204 - acc: 0.1884 - val_loss: 2.2236 - val_acc: 0.1740\n","Epoch 135/150\n","30/30 [==============================] - 0s 4ms/step - loss: 2.2187 - acc: 0.1884 - val_loss: 2.2219 - val_acc: 0.1740\n","Epoch 136/150\n","30/30 [==============================] - 0s 4ms/step - loss: 2.2170 - acc: 0.1884 - val_loss: 2.2202 - val_acc: 0.1740\n","Epoch 137/150\n","30/30 [==============================] - 0s 5ms/step - loss: 2.2152 - acc: 0.1884 - val_loss: 2.2184 - val_acc: 0.1740\n","Epoch 138/150\n","30/30 [==============================] - 0s 4ms/step - loss: 2.2135 - acc: 0.1884 - val_loss: 2.2167 - val_acc: 0.1740\n","Epoch 139/150\n","30/30 [==============================] - 0s 4ms/step - loss: 2.2118 - acc: 0.1884 - val_loss: 2.2150 - val_acc: 0.1740\n","Epoch 140/150\n","30/30 [==============================] - 0s 4ms/step - loss: 2.2101 - acc: 0.1884 - val_loss: 2.2133 - val_acc: 0.1740\n","Epoch 141/150\n","30/30 [==============================] - 0s 4ms/step - loss: 2.2084 - acc: 0.1884 - val_loss: 2.2116 - val_acc: 0.1740\n","Epoch 142/150\n","30/30 [==============================] - 0s 4ms/step - loss: 2.2067 - acc: 0.1884 - val_loss: 2.2099 - val_acc: 0.1740\n","Epoch 143/150\n","30/30 [==============================] - 0s 4ms/step - loss: 2.2051 - acc: 0.1884 - val_loss: 2.2083 - val_acc: 0.1740\n","Epoch 144/150\n","30/30 [==============================] - 0s 4ms/step - loss: 2.2034 - acc: 0.1884 - val_loss: 2.2066 - val_acc: 0.1740\n","Epoch 145/150\n","30/30 [==============================] - 0s 4ms/step - loss: 2.2018 - acc: 0.1884 - val_loss: 2.2050 - val_acc: 0.1740\n","Epoch 146/150\n","30/30 [==============================] - 0s 4ms/step - loss: 2.2001 - acc: 0.1884 - val_loss: 2.2033 - val_acc: 0.1740\n","Epoch 147/150\n","30/30 [==============================] - 0s 4ms/step - loss: 2.1985 - acc: 0.1884 - val_loss: 2.2017 - val_acc: 0.1740\n","Epoch 148/150\n","30/30 [==============================] - 0s 4ms/step - loss: 2.1969 - acc: 0.1884 - val_loss: 2.2001 - val_acc: 0.1740\n","Epoch 149/150\n","30/30 [==============================] - 0s 4ms/step - loss: 2.1953 - acc: 0.1884 - val_loss: 2.1985 - val_acc: 0.1740\n","Epoch 150/150\n","30/30 [==============================] - 0s 4ms/step - loss: 2.1937 - acc: 0.1884 - val_loss: 2.1969 - val_acc: 0.1740\n"]}],"source":["# Import regularizers\n","from keras import regularizers\n","\n","random.seed(123)\n","L2_model = models.Sequential()\n","\n","# Add the input and first hidden layer\n","L2_model.add(layers.Dense(50, activation='relu', kernel_regularizer=regularizers.l2(0.005), input_shape=(2000, )))\n","\n","# Add another hidden layer\n","L2_model.add(layers.Dense(25, activation='relu', kernel_regularizer=regularizers.l2(0.005)))\n","\n","# Add an output layer\n","L2_model.add(layers.Dense(7, activation='softmax'))\n","\n","# Compile the model\n","L2_model.compile(optimizer='SGD', \n","                 loss='categorical_crossentropy', \n","                 metrics=['acc'])\n","\n","# Train the model \n","L2_model_val = L2_model.fit(X_train_tokens, \n","                            y_train_lb, \n","                            epochs=150, \n","                            batch_size=256, \n","                            validation_data=(X_val_tokens, y_val_lb))"]},{"cell_type":"markdown","metadata":{},"source":["Now, look at the training as well as the validation accuracy for both the L2 and the baseline models. "]},{"cell_type":"code","execution_count":88,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 864x576 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["# L2 model details\n","L2_model_dict = L2_model_val.history\n","L2_acc_values = L2_model_dict['acc'] \n","L2_val_acc_values = L2_model_dict['val_acc']\n","\n","# Baseline model\n","baseline_model_acc = baseline_model_val_dict['acc'] \n","baseline_model_val_acc = baseline_model_val_dict['val_acc']\n","\n","# Plot the accuracy for these models\n","fig, ax = plt.subplots(figsize=(12, 8))\n","epochs = range(1, len(acc_values) + 1)\n","ax.plot(epochs, L2_acc_values, label='Training acc L2')\n","ax.plot(epochs, L2_val_acc_values, label='Validation acc L2')\n","ax.plot(epochs, baseline_model_acc, label='Training acc')\n","ax.plot(epochs, baseline_model_val_acc, label='Validation acc')\n","ax.set_title('Training & validation accuracy L2 vs regular')\n","ax.set_xlabel('Epochs')\n","ax.set_ylabel('Accuracy')\n","ax.legend();"]},{"cell_type":"markdown","metadata":{},"source":["The results of L2 regularization are quite disappointing here. Notice the discrepancy between validation and training accuracy seems to have decreased slightly, but the end result is definitely not getting better.  \n","\n","\n","## L1 Regularization\n","\n","Now have a look at L1 regularization. Will this work better? \n","\n","- Use 2 hidden layers with 50 units in the first and 25 in the second layer, both with `'relu'` activation functions \n","- Add L1 regularization to both the hidden layers with 0.005 as the `lambda_coeff` "]},{"cell_type":"code","execution_count":89,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/150\n","30/30 [==============================] - 0s 6ms/step - loss: 16.0236 - acc: 0.1881 - val_loss: 15.6294 - val_acc: 0.1740\n","Epoch 2/150\n","30/30 [==============================] - 0s 3ms/step - loss: 15.2836 - acc: 0.1884 - val_loss: 14.9007 - val_acc: 0.1740\n","Epoch 3/150\n","30/30 [==============================] - 0s 3ms/step - loss: 14.5644 - acc: 0.1884 - val_loss: 14.1925 - val_acc: 0.1740\n","Epoch 4/150\n","30/30 [==============================] - 0s 3ms/step - loss: 13.8658 - acc: 0.1884 - val_loss: 13.5050 - val_acc: 0.1740\n","Epoch 5/150\n","30/30 [==============================] - 0s 3ms/step - loss: 13.1880 - acc: 0.1884 - val_loss: 12.8384 - val_acc: 0.1740\n","Epoch 6/150\n","30/30 [==============================] - 0s 4ms/step - loss: 12.5311 - acc: 0.1884 - val_loss: 12.1929 - val_acc: 0.1740\n","Epoch 7/150\n","30/30 [==============================] - 0s 3ms/step - loss: 11.8953 - acc: 0.1884 - val_loss: 11.5681 - val_acc: 0.1740\n","Epoch 8/150\n","30/30 [==============================] - 0s 3ms/step - loss: 11.2802 - acc: 0.1884 - val_loss: 10.9642 - val_acc: 0.1740\n","Epoch 9/150\n","30/30 [==============================] - 0s 3ms/step - loss: 10.6859 - acc: 0.1884 - val_loss: 10.3811 - val_acc: 0.1740\n","Epoch 10/150\n","30/30 [==============================] - 0s 3ms/step - loss: 10.1127 - acc: 0.1884 - val_loss: 9.8190 - val_acc: 0.1740\n","Epoch 11/150\n","30/30 [==============================] - 0s 4ms/step - loss: 9.5601 - acc: 0.1884 - val_loss: 9.2774 - val_acc: 0.1740\n","Epoch 12/150\n","30/30 [==============================] - 0s 3ms/step - loss: 9.0279 - acc: 0.1884 - val_loss: 8.7560 - val_acc: 0.1740\n","Epoch 13/150\n","30/30 [==============================] - 0s 4ms/step - loss: 8.5162 - acc: 0.1884 - val_loss: 8.2556 - val_acc: 0.1740\n","Epoch 14/150\n","30/30 [==============================] - 0s 5ms/step - loss: 8.0257 - acc: 0.1884 - val_loss: 7.7762 - val_acc: 0.1740\n","Epoch 15/150\n","30/30 [==============================] - 0s 3ms/step - loss: 7.5563 - acc: 0.1884 - val_loss: 7.3182 - val_acc: 0.1740\n","Epoch 16/150\n","30/30 [==============================] - 0s 3ms/step - loss: 7.1082 - acc: 0.1884 - val_loss: 6.8814 - val_acc: 0.1740\n","Epoch 17/150\n","30/30 [==============================] - 0s 3ms/step - loss: 6.6813 - acc: 0.1884 - val_loss: 6.4660 - val_acc: 0.1740\n","Epoch 18/150\n","30/30 [==============================] - 0s 3ms/step - loss: 6.2755 - acc: 0.1884 - val_loss: 6.0709 - val_acc: 0.1740\n","Epoch 19/150\n","30/30 [==============================] - 0s 4ms/step - loss: 5.8898 - acc: 0.1884 - val_loss: 5.6959 - val_acc: 0.1740\n","Epoch 20/150\n","30/30 [==============================] - 0s 3ms/step - loss: 5.5245 - acc: 0.1884 - val_loss: 5.3417 - val_acc: 0.1740\n","Epoch 21/150\n","30/30 [==============================] - 0s 3ms/step - loss: 5.1801 - acc: 0.1884 - val_loss: 5.0084 - val_acc: 0.1740\n","Epoch 22/150\n","30/30 [==============================] - 0s 4ms/step - loss: 4.8566 - acc: 0.1884 - val_loss: 4.6960 - val_acc: 0.1740\n","Epoch 23/150\n","30/30 [==============================] - 0s 5ms/step - loss: 4.5537 - acc: 0.1884 - val_loss: 4.4041 - val_acc: 0.1740\n","Epoch 24/150\n","30/30 [==============================] - 0s 3ms/step - loss: 4.2716 - acc: 0.1884 - val_loss: 4.1331 - val_acc: 0.1740\n","Epoch 25/150\n","30/30 [==============================] - 0s 3ms/step - loss: 4.0107 - acc: 0.1884 - val_loss: 3.8837 - val_acc: 0.1740\n","Epoch 26/150\n","30/30 [==============================] - 0s 3ms/step - loss: 3.7712 - acc: 0.1884 - val_loss: 3.6554 - val_acc: 0.1740\n","Epoch 27/150\n","30/30 [==============================] - 0s 3ms/step - loss: 3.5529 - acc: 0.1884 - val_loss: 3.4484 - val_acc: 0.1740\n","Epoch 28/150\n","30/30 [==============================] - 0s 3ms/step - loss: 3.3558 - acc: 0.1884 - val_loss: 3.2624 - val_acc: 0.1740\n","Epoch 29/150\n","30/30 [==============================] - 0s 4ms/step - loss: 3.1797 - acc: 0.1884 - val_loss: 3.0975 - val_acc: 0.1740\n","Epoch 30/150\n","30/30 [==============================] - 0s 3ms/step - loss: 3.0244 - acc: 0.1884 - val_loss: 2.9532 - val_acc: 0.1740\n","Epoch 31/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.8899 - acc: 0.1884 - val_loss: 2.8297 - val_acc: 0.1740\n","Epoch 32/150\n","30/30 [==============================] - 0s 4ms/step - loss: 2.7761 - acc: 0.1884 - val_loss: 2.7269 - val_acc: 0.1740\n","Epoch 33/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.6832 - acc: 0.1884 - val_loss: 2.6451 - val_acc: 0.1740\n","Epoch 34/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.6112 - acc: 0.1884 - val_loss: 2.5840 - val_acc: 0.1740\n","Epoch 35/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.5598 - acc: 0.1884 - val_loss: 2.5438 - val_acc: 0.1740\n","Epoch 36/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.5296 - acc: 0.1884 - val_loss: 2.5247 - val_acc: 0.1740\n","Epoch 37/150\n","30/30 [==============================] - 0s 4ms/step - loss: 2.5176 - acc: 0.1884 - val_loss: 2.5171 - val_acc: 0.1740\n","Epoch 38/150\n","30/30 [==============================] - 0s 4ms/step - loss: 2.5100 - acc: 0.1884 - val_loss: 2.5095 - val_acc: 0.1740\n","Epoch 39/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.5024 - acc: 0.1884 - val_loss: 2.5019 - val_acc: 0.1740\n","Epoch 40/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.4948 - acc: 0.1884 - val_loss: 2.4945 - val_acc: 0.1740\n","Epoch 41/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.4873 - acc: 0.1884 - val_loss: 2.4870 - val_acc: 0.1740\n","Epoch 42/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.4799 - acc: 0.1884 - val_loss: 2.4797 - val_acc: 0.1740\n","Epoch 43/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.4726 - acc: 0.1884 - val_loss: 2.4724 - val_acc: 0.1740\n","Epoch 44/150\n","30/30 [==============================] - 0s 4ms/step - loss: 2.4652 - acc: 0.1884 - val_loss: 2.4651 - val_acc: 0.1740\n","Epoch 45/150\n","30/30 [==============================] - 0s 4ms/step - loss: 2.4580 - acc: 0.1884 - val_loss: 2.4579 - val_acc: 0.1740\n","Epoch 46/150\n","30/30 [==============================] - 0s 4ms/step - loss: 2.4508 - acc: 0.1884 - val_loss: 2.4507 - val_acc: 0.1740\n","Epoch 47/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.4436 - acc: 0.1884 - val_loss: 2.4435 - val_acc: 0.1740\n","Epoch 48/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.4365 - acc: 0.1884 - val_loss: 2.4365 - val_acc: 0.1740\n","Epoch 49/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.4294 - acc: 0.1884 - val_loss: 2.4294 - val_acc: 0.1740\n","Epoch 50/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.4224 - acc: 0.1884 - val_loss: 2.4225 - val_acc: 0.1740\n","Epoch 51/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.4154 - acc: 0.1884 - val_loss: 2.4156 - val_acc: 0.1740\n","Epoch 52/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.4086 - acc: 0.1884 - val_loss: 2.4087 - val_acc: 0.1740\n","Epoch 53/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.4017 - acc: 0.1884 - val_loss: 2.4020 - val_acc: 0.1740\n","Epoch 54/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.3949 - acc: 0.1884 - val_loss: 2.3952 - val_acc: 0.1740\n","Epoch 55/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.3882 - acc: 0.1884 - val_loss: 2.3885 - val_acc: 0.1740\n","Epoch 56/150\n","30/30 [==============================] - 0s 4ms/step - loss: 2.3815 - acc: 0.1884 - val_loss: 2.3819 - val_acc: 0.1740\n","Epoch 57/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.3749 - acc: 0.1884 - val_loss: 2.3753 - val_acc: 0.1740\n","Epoch 58/150\n","30/30 [==============================] - 0s 4ms/step - loss: 2.3683 - acc: 0.1884 - val_loss: 2.3687 - val_acc: 0.1740\n","Epoch 59/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.3618 - acc: 0.1884 - val_loss: 2.3623 - val_acc: 0.1740\n","Epoch 60/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.3553 - acc: 0.1884 - val_loss: 2.3558 - val_acc: 0.1740\n","Epoch 61/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.3489 - acc: 0.1884 - val_loss: 2.3495 - val_acc: 0.1740\n","Epoch 62/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.3425 - acc: 0.1884 - val_loss: 2.3431 - val_acc: 0.1740\n","Epoch 63/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.3362 - acc: 0.1884 - val_loss: 2.3369 - val_acc: 0.1740\n","Epoch 64/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.3299 - acc: 0.1884 - val_loss: 2.3306 - val_acc: 0.1740\n","Epoch 65/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.3237 - acc: 0.1884 - val_loss: 2.3244 - val_acc: 0.1740\n","Epoch 66/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.3176 - acc: 0.1884 - val_loss: 2.3183 - val_acc: 0.1740\n","Epoch 67/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.3115 - acc: 0.1884 - val_loss: 2.3122 - val_acc: 0.1740\n","Epoch 68/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.3054 - acc: 0.1884 - val_loss: 2.3062 - val_acc: 0.1740\n","Epoch 69/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.2994 - acc: 0.1884 - val_loss: 2.3002 - val_acc: 0.1740\n","Epoch 70/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.2934 - acc: 0.1884 - val_loss: 2.2943 - val_acc: 0.1740\n","Epoch 71/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.2874 - acc: 0.1884 - val_loss: 2.2883 - val_acc: 0.1740\n","Epoch 72/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.2815 - acc: 0.1884 - val_loss: 2.2824 - val_acc: 0.1740\n","Epoch 73/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.2756 - acc: 0.1884 - val_loss: 2.2766 - val_acc: 0.1740\n","Epoch 74/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.2698 - acc: 0.1884 - val_loss: 2.2708 - val_acc: 0.1740\n","Epoch 75/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.2640 - acc: 0.1884 - val_loss: 2.2650 - val_acc: 0.1740\n","Epoch 76/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.2583 - acc: 0.1884 - val_loss: 2.2593 - val_acc: 0.1740\n","Epoch 77/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.2526 - acc: 0.1884 - val_loss: 2.2536 - val_acc: 0.1740\n","Epoch 78/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.2469 - acc: 0.1884 - val_loss: 2.2480 - val_acc: 0.1740\n","Epoch 79/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.2413 - acc: 0.1884 - val_loss: 2.2424 - val_acc: 0.1740\n","Epoch 80/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.2357 - acc: 0.1884 - val_loss: 2.2368 - val_acc: 0.1740\n","Epoch 81/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.2302 - acc: 0.1884 - val_loss: 2.2313 - val_acc: 0.1740\n","Epoch 82/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.2247 - acc: 0.1884 - val_loss: 2.2259 - val_acc: 0.1740\n","Epoch 83/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.2193 - acc: 0.1884 - val_loss: 2.2205 - val_acc: 0.1740\n","Epoch 84/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.2140 - acc: 0.1884 - val_loss: 2.2152 - val_acc: 0.1740\n","Epoch 85/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.2087 - acc: 0.1884 - val_loss: 2.2100 - val_acc: 0.1740\n","Epoch 86/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.2035 - acc: 0.1884 - val_loss: 2.2048 - val_acc: 0.1740\n","Epoch 87/150\n","30/30 [==============================] - 0s 4ms/step - loss: 2.1983 - acc: 0.1884 - val_loss: 2.1996 - val_acc: 0.1740\n","Epoch 88/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.1932 - acc: 0.1884 - val_loss: 2.1946 - val_acc: 0.1740\n","Epoch 89/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.1882 - acc: 0.1884 - val_loss: 2.1896 - val_acc: 0.1740\n","Epoch 90/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.1832 - acc: 0.1884 - val_loss: 2.1846 - val_acc: 0.1740\n","Epoch 91/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.1783 - acc: 0.1884 - val_loss: 2.1797 - val_acc: 0.1740\n","Epoch 92/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.1734 - acc: 0.1884 - val_loss: 2.1749 - val_acc: 0.1740\n","Epoch 93/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.1686 - acc: 0.1884 - val_loss: 2.1701 - val_acc: 0.1740\n","Epoch 94/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.1638 - acc: 0.1884 - val_loss: 2.1654 - val_acc: 0.1740\n","Epoch 95/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.1591 - acc: 0.1884 - val_loss: 2.1607 - val_acc: 0.1740\n","Epoch 96/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.1545 - acc: 0.1884 - val_loss: 2.1561 - val_acc: 0.1740\n","Epoch 97/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.1498 - acc: 0.1884 - val_loss: 2.1515 - val_acc: 0.1740\n","Epoch 98/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.1453 - acc: 0.1884 - val_loss: 2.1470 - val_acc: 0.1740\n","Epoch 99/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.1408 - acc: 0.1884 - val_loss: 2.1425 - val_acc: 0.1740\n","Epoch 100/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.1364 - acc: 0.1884 - val_loss: 2.1381 - val_acc: 0.1740\n","Epoch 101/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.1320 - acc: 0.1884 - val_loss: 2.1338 - val_acc: 0.1740\n","Epoch 102/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.1277 - acc: 0.1884 - val_loss: 2.1295 - val_acc: 0.1740\n","Epoch 103/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.1234 - acc: 0.1884 - val_loss: 2.1252 - val_acc: 0.1740\n","Epoch 104/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.1192 - acc: 0.1884 - val_loss: 2.1210 - val_acc: 0.1740\n","Epoch 105/150\n","30/30 [==============================] - 0s 4ms/step - loss: 2.1150 - acc: 0.1884 - val_loss: 2.1169 - val_acc: 0.1740\n","Epoch 106/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.1109 - acc: 0.1884 - val_loss: 2.1128 - val_acc: 0.1740\n","Epoch 107/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.1068 - acc: 0.1884 - val_loss: 2.1087 - val_acc: 0.1740\n","Epoch 108/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.1027 - acc: 0.1884 - val_loss: 2.1047 - val_acc: 0.1740\n","Epoch 109/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.0988 - acc: 0.1884 - val_loss: 2.1008 - val_acc: 0.1740\n","Epoch 110/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.0948 - acc: 0.1884 - val_loss: 2.0969 - val_acc: 0.1740\n","Epoch 111/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.0910 - acc: 0.1884 - val_loss: 2.0931 - val_acc: 0.1740\n","Epoch 112/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.0872 - acc: 0.1884 - val_loss: 2.0893 - val_acc: 0.1740\n","Epoch 113/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.0834 - acc: 0.1884 - val_loss: 2.0855 - val_acc: 0.1740\n","Epoch 114/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.0796 - acc: 0.1884 - val_loss: 2.0818 - val_acc: 0.1740\n","Epoch 115/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.0759 - acc: 0.1884 - val_loss: 2.0781 - val_acc: 0.1740\n","Epoch 116/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.0723 - acc: 0.1884 - val_loss: 2.0745 - val_acc: 0.1740\n","Epoch 117/150\n","30/30 [==============================] - 0s 4ms/step - loss: 2.0688 - acc: 0.1884 - val_loss: 2.0710 - val_acc: 0.1740\n","Epoch 118/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.0653 - acc: 0.1884 - val_loss: 2.0676 - val_acc: 0.1740\n","Epoch 119/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.0619 - acc: 0.1884 - val_loss: 2.0643 - val_acc: 0.1740\n","Epoch 120/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.0586 - acc: 0.1884 - val_loss: 2.0610 - val_acc: 0.1740\n","Epoch 121/150\n","30/30 [==============================] - 0s 4ms/step - loss: 2.0553 - acc: 0.1884 - val_loss: 2.0577 - val_acc: 0.1740\n","Epoch 122/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.0521 - acc: 0.1884 - val_loss: 2.0545 - val_acc: 0.1740\n","Epoch 123/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.0488 - acc: 0.1884 - val_loss: 2.0513 - val_acc: 0.1740\n","Epoch 124/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.0457 - acc: 0.1884 - val_loss: 2.0481 - val_acc: 0.1740\n","Epoch 125/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.0426 - acc: 0.1884 - val_loss: 2.0450 - val_acc: 0.1740\n","Epoch 126/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.0395 - acc: 0.1884 - val_loss: 2.0420 - val_acc: 0.1740\n","Epoch 127/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.0365 - acc: 0.1884 - val_loss: 2.0390 - val_acc: 0.1740\n","Epoch 128/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.0335 - acc: 0.1884 - val_loss: 2.0361 - val_acc: 0.1740\n","Epoch 129/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.0306 - acc: 0.1884 - val_loss: 2.0332 - val_acc: 0.1740\n","Epoch 130/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.0277 - acc: 0.1884 - val_loss: 2.0304 - val_acc: 0.1740\n","Epoch 131/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.0249 - acc: 0.1884 - val_loss: 2.0276 - val_acc: 0.1740\n","Epoch 132/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.0222 - acc: 0.1884 - val_loss: 2.0249 - val_acc: 0.1740\n","Epoch 133/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.0194 - acc: 0.1884 - val_loss: 2.0222 - val_acc: 0.1740\n","Epoch 134/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.0167 - acc: 0.1884 - val_loss: 2.0195 - val_acc: 0.1740\n","Epoch 135/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.0141 - acc: 0.1884 - val_loss: 2.0169 - val_acc: 0.1740\n","Epoch 136/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.0115 - acc: 0.1884 - val_loss: 2.0144 - val_acc: 0.1740\n","Epoch 137/150\n","30/30 [==============================] - 0s 4ms/step - loss: 2.0090 - acc: 0.1884 - val_loss: 2.0118 - val_acc: 0.1740\n","Epoch 138/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.0065 - acc: 0.1884 - val_loss: 2.0093 - val_acc: 0.1740\n","Epoch 139/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.0040 - acc: 0.1884 - val_loss: 2.0069 - val_acc: 0.1740\n","Epoch 140/150\n","30/30 [==============================] - 0s 3ms/step - loss: 2.0017 - acc: 0.1884 - val_loss: 2.0046 - val_acc: 0.1740\n","Epoch 141/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9993 - acc: 0.1884 - val_loss: 2.0023 - val_acc: 0.1740\n","Epoch 142/150\n","30/30 [==============================] - 0s 4ms/step - loss: 1.9970 - acc: 0.1884 - val_loss: 2.0000 - val_acc: 0.1740\n","Epoch 143/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9948 - acc: 0.1884 - val_loss: 1.9977 - val_acc: 0.1740\n","Epoch 144/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9926 - acc: 0.1884 - val_loss: 1.9956 - val_acc: 0.1740\n","Epoch 145/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9904 - acc: 0.1884 - val_loss: 1.9934 - val_acc: 0.1740\n","Epoch 146/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9883 - acc: 0.1884 - val_loss: 1.9913 - val_acc: 0.1740\n","Epoch 147/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9862 - acc: 0.1884 - val_loss: 1.9892 - val_acc: 0.1740\n","Epoch 148/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9841 - acc: 0.1884 - val_loss: 1.9872 - val_acc: 0.1740\n","Epoch 149/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9821 - acc: 0.1884 - val_loss: 1.9852 - val_acc: 0.1740\n","Epoch 150/150\n","30/30 [==============================] - 0s 3ms/step - loss: 1.9801 - acc: 0.1884 - val_loss: 1.9832 - val_acc: 0.1740\n"]}],"source":["random.seed(123)\n","L1_model = models.Sequential()\n","\n","# Add the input and first hidden layer\n","L1_model.add(layers.Dense(50, activation='relu', kernel_regularizer=regularizers.l1(0.005), input_shape=(2000, )))\n","\n","# Add another hidden layer\n","L1_model.add(layers.Dense(25, activation='relu', kernel_regularizer=regularizers.l1(0.005)))\n","\n","\n","# Add an output layer\n","L1_model.add(layers.Dense(7, activation='softmax'))\n","\n","# Compile the model\n","L1_model.compile(optimizer='SGD', \n","                 loss='categorical_crossentropy', \n","                 metrics=['acc'])\n","\n","# Train the model \n","L1_model_val = L1_model.fit(X_train_tokens, \n","                            y_train_lb, \n","                            epochs=150, \n","                            batch_size=256, \n","                            validation_data=(X_val_tokens, y_val_lb))"]},{"cell_type":"markdown","metadata":{},"source":["Plot the training as well as the validation accuracy for the L1 model: "]},{"cell_type":"code","execution_count":90,"metadata":{"scrolled":true},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 864x576 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["fig, ax = plt.subplots(figsize=(12, 8))\n","\n","L1_model_dict = L1_model_val.history\n","\n","acc_values = L1_model_dict['acc'] \n","val_acc_values = L1_model_dict['val_acc']\n","\n","epochs = range(1, len(acc_values) + 1)\n","ax.plot(epochs, acc_values, label='Training acc L1')\n","ax.plot(epochs, val_acc_values, label='Validation acc L1')\n","ax.set_title('Training & validation accuracy with L1 regularization')\n","ax.set_xlabel('Epochs')\n","ax.set_ylabel('Accuracy')\n","ax.legend();"]},{"cell_type":"markdown","metadata":{},"source":["Notice how the training and validation accuracy don't diverge as much as before. Unfortunately, the validation accuracy isn't still that good. Next, experiment with dropout regularization to see if it offers any advantages. \n","\n","\n","## Dropout Regularization \n","\n","It's time to try another technique: applying dropout to layers. As discussed in the earlier lesson, this involves setting a certain proportion of units in each layer to zero. In the following cell: \n","\n","- Apply a dropout rate of 30% to the input layer \n","- Add a first hidden layer with 50 units and `'relu'` activation \n","- Apply a dropout rate of 30% to the first hidden layer \n","- Add a second hidden layer with 25 units and `'relu'` activation \n","- Apply a dropout rate of 30% to the second hidden layer \n"]},{"cell_type":"code","execution_count":91,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/150\n","30/30 [==============================] - 0s 9ms/step - loss: 1.9452 - acc: 0.1841 - val_loss: 1.9446 - val_acc: 0.1740\n","Epoch 2/150\n","30/30 [==============================] - 0s 7ms/step - loss: 1.9438 - acc: 0.1884 - val_loss: 1.9435 - val_acc: 0.1740\n","Epoch 3/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9425 - acc: 0.1884 - val_loss: 1.9424 - val_acc: 0.1740\n","Epoch 4/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9413 - acc: 0.1884 - val_loss: 1.9415 - val_acc: 0.1740\n","Epoch 5/150\n","30/30 [==============================] - 0s 7ms/step - loss: 1.9402 - acc: 0.1884 - val_loss: 1.9406 - val_acc: 0.1740\n","Epoch 6/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9392 - acc: 0.1884 - val_loss: 1.9398 - val_acc: 0.1740\n","Epoch 7/150\n","30/30 [==============================] - 0s 7ms/step - loss: 1.9383 - acc: 0.1884 - val_loss: 1.9390 - val_acc: 0.1740\n","Epoch 8/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9375 - acc: 0.1884 - val_loss: 1.9384 - val_acc: 0.1740\n","Epoch 9/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9367 - acc: 0.1884 - val_loss: 1.9378 - val_acc: 0.1740\n","Epoch 10/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9360 - acc: 0.1884 - val_loss: 1.9372 - val_acc: 0.1740\n","Epoch 11/150\n","30/30 [==============================] - 0s 7ms/step - loss: 1.9353 - acc: 0.1884 - val_loss: 1.9367 - val_acc: 0.1740\n","Epoch 12/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9347 - acc: 0.1884 - val_loss: 1.9362 - val_acc: 0.1740\n","Epoch 13/150\n","30/30 [==============================] - 0s 7ms/step - loss: 1.9342 - acc: 0.1884 - val_loss: 1.9358 - val_acc: 0.1740\n","Epoch 14/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9336 - acc: 0.1884 - val_loss: 1.9354 - val_acc: 0.1740\n","Epoch 15/150\n","30/30 [==============================] - 0s 5ms/step - loss: 1.9332 - acc: 0.1884 - val_loss: 1.9350 - val_acc: 0.1740\n","Epoch 16/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9328 - acc: 0.1884 - val_loss: 1.9347 - val_acc: 0.1740\n","Epoch 17/150\n","30/30 [==============================] - 0s 7ms/step - loss: 1.9324 - acc: 0.1884 - val_loss: 1.9344 - val_acc: 0.1740\n","Epoch 18/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9320 - acc: 0.1884 - val_loss: 1.9342 - val_acc: 0.1740\n","Epoch 19/150\n","30/30 [==============================] - 0s 7ms/step - loss: 1.9317 - acc: 0.1884 - val_loss: 1.9340 - val_acc: 0.1740\n","Epoch 20/150\n","30/30 [==============================] - 0s 5ms/step - loss: 1.9314 - acc: 0.1884 - val_loss: 1.9338 - val_acc: 0.1740\n","Epoch 21/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9311 - acc: 0.1884 - val_loss: 1.9336 - val_acc: 0.1740\n","Epoch 22/150\n","30/30 [==============================] - 0s 7ms/step - loss: 1.9308 - acc: 0.1884 - val_loss: 1.9334 - val_acc: 0.1740\n","Epoch 23/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9306 - acc: 0.1884 - val_loss: 1.9332 - val_acc: 0.1740\n","Epoch 24/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9304 - acc: 0.1884 - val_loss: 1.9331 - val_acc: 0.1740\n","Epoch 25/150\n","30/30 [==============================] - 0s 7ms/step - loss: 1.9302 - acc: 0.1884 - val_loss: 1.9330 - val_acc: 0.1740\n","Epoch 26/150\n","30/30 [==============================] - 0s 7ms/step - loss: 1.9300 - acc: 0.1884 - val_loss: 1.9329 - val_acc: 0.1740\n","Epoch 27/150\n","30/30 [==============================] - 0s 7ms/step - loss: 1.9298 - acc: 0.1884 - val_loss: 1.9328 - val_acc: 0.1740\n","Epoch 28/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9297 - acc: 0.1884 - val_loss: 1.9327 - val_acc: 0.1740\n","Epoch 29/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9295 - acc: 0.1884 - val_loss: 1.9326 - val_acc: 0.1740\n","Epoch 30/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9294 - acc: 0.1884 - val_loss: 1.9325 - val_acc: 0.1740\n","Epoch 31/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9293 - acc: 0.1884 - val_loss: 1.9324 - val_acc: 0.1740\n","Epoch 32/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9292 - acc: 0.1884 - val_loss: 1.9324 - val_acc: 0.1740\n","Epoch 33/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9291 - acc: 0.1884 - val_loss: 1.9323 - val_acc: 0.1740\n","Epoch 34/150\n","30/30 [==============================] - 0s 5ms/step - loss: 1.9290 - acc: 0.1884 - val_loss: 1.9323 - val_acc: 0.1740\n","Epoch 35/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9289 - acc: 0.1884 - val_loss: 1.9322 - val_acc: 0.1740\n","Epoch 36/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9288 - acc: 0.1884 - val_loss: 1.9322 - val_acc: 0.1740\n","Epoch 37/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9287 - acc: 0.1884 - val_loss: 1.9321 - val_acc: 0.1740\n","Epoch 38/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9287 - acc: 0.1884 - val_loss: 1.9321 - val_acc: 0.1740\n","Epoch 39/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9286 - acc: 0.1884 - val_loss: 1.9321 - val_acc: 0.1740\n","Epoch 40/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9285 - acc: 0.1884 - val_loss: 1.9321 - val_acc: 0.1740\n","Epoch 41/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9285 - acc: 0.1884 - val_loss: 1.9320 - val_acc: 0.1740\n","Epoch 42/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9284 - acc: 0.1884 - val_loss: 1.9320 - val_acc: 0.1740\n","Epoch 43/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9284 - acc: 0.1884 - val_loss: 1.9320 - val_acc: 0.1740\n","Epoch 44/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9284 - acc: 0.1884 - val_loss: 1.9320 - val_acc: 0.1740\n","Epoch 45/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9283 - acc: 0.1884 - val_loss: 1.9320 - val_acc: 0.1740\n","Epoch 46/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9283 - acc: 0.1884 - val_loss: 1.9320 - val_acc: 0.1740\n","Epoch 47/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9282 - acc: 0.1884 - val_loss: 1.9320 - val_acc: 0.1740\n","Epoch 48/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9282 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 49/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9282 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 50/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9282 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 51/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9281 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 52/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9281 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 53/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9281 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 54/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9281 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 55/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9281 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 56/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9280 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 57/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9280 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 58/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9280 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 59/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9280 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 60/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9280 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 61/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9280 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 62/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9280 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 63/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9280 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 64/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9279 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 65/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9279 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 66/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9279 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 67/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9279 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 68/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9279 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 69/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9279 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 70/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9279 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 71/150\n","30/30 [==============================] - 0s 7ms/step - loss: 1.9279 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 72/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9279 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 73/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9279 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 74/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9279 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 75/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9279 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 76/150\n","30/30 [==============================] - 0s 8ms/step - loss: 1.9279 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 77/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9279 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 78/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9279 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 79/150\n","30/30 [==============================] - 0s 7ms/step - loss: 1.9279 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 80/150\n","30/30 [==============================] - 0s 7ms/step - loss: 1.9279 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 81/150\n","30/30 [==============================] - 0s 7ms/step - loss: 1.9279 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 82/150\n","30/30 [==============================] - 0s 7ms/step - loss: 1.9279 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 83/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9279 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 84/150\n","30/30 [==============================] - 0s 7ms/step - loss: 1.9279 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 85/150\n","30/30 [==============================] - 0s 7ms/step - loss: 1.9279 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 86/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9279 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 87/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9279 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 88/150\n","30/30 [==============================] - 0s 8ms/step - loss: 1.9279 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 89/150\n","30/30 [==============================] - 0s 7ms/step - loss: 1.9279 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 90/150\n","30/30 [==============================] - 0s 7ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 91/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 92/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 93/150\n","30/30 [==============================] - 0s 5ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 94/150\n","30/30 [==============================] - 0s 5ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 95/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 96/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 97/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 98/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 99/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 100/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 101/150\n","30/30 [==============================] - 0s 7ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 102/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 103/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 104/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 105/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 106/150\n","30/30 [==============================] - 0s 7ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 107/150\n","30/30 [==============================] - 0s 7ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 108/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 109/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 110/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 111/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 112/150\n","30/30 [==============================] - 0s 5ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 113/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 114/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 115/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 116/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 117/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 118/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 119/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 120/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 121/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 122/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 123/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 124/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 125/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 126/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9320 - val_acc: 0.1740\n","Epoch 127/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9320 - val_acc: 0.1740\n","Epoch 128/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 129/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9320 - val_acc: 0.1740\n","Epoch 130/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9320 - val_acc: 0.1740\n","Epoch 131/150\n","30/30 [==============================] - 0s 7ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9320 - val_acc: 0.1740\n","Epoch 132/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9320 - val_acc: 0.1740\n","Epoch 133/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9320 - val_acc: 0.1740\n","Epoch 134/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9320 - val_acc: 0.1740\n","Epoch 135/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9320 - val_acc: 0.1740\n","Epoch 136/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9320 - val_acc: 0.1740\n","Epoch 137/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9320 - val_acc: 0.1740\n","Epoch 138/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9320 - val_acc: 0.1740\n","Epoch 139/150\n","30/30 [==============================] - 0s 5ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9320 - val_acc: 0.1740\n","Epoch 140/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9320 - val_acc: 0.1740\n","Epoch 141/150\n","30/30 [==============================] - 0s 5ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9320 - val_acc: 0.1740\n","Epoch 142/150\n","30/30 [==============================] - 0s 5ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 143/150\n","30/30 [==============================] - 0s 5ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9320 - val_acc: 0.1740\n","Epoch 144/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9320 - val_acc: 0.1740\n","Epoch 145/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9320 - val_acc: 0.1740\n","Epoch 146/150\n","30/30 [==============================] - 0s 6ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9320 - val_acc: 0.1740\n","Epoch 147/150\n","30/30 [==============================] - 0s 5ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 148/150\n","30/30 [==============================] - 0s 5ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 149/150\n","30/30 [==============================] - 0s 5ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n","Epoch 150/150\n","30/30 [==============================] - 0s 5ms/step - loss: 1.9278 - acc: 0.1884 - val_loss: 1.9319 - val_acc: 0.1740\n"]}],"source":["# ⏰ This cell may take about a minute to run\n","random.seed(123)\n","dropout_model = models.Sequential()\n","\n","# Implement dropout to the input layer\n","# NOTE: This is where you define the number of units in the input layer\n","dropout_model.add(layers.Dropout(0.3, input_shape=(2000, )))\n","\n","# Add the first hidden layer\n","dropout_model.add(layers.Dense(50, activation='relu'))\n","\n","# Implement dropout to the first hidden layer \n","dropout_model.add(layers.Dropout(0.3))\n","\n","# Add the second hidden layer\n","dropout_model.add(layers.Dense(25, activation='relu'))\n","\n","# Implement dropout to the second hidden layer \n","dropout_model.add(layers.Dropout(0.3))\n","\n","# Add the output layer\n","dropout_model.add(layers.Dense(7, activation='softmax'))\n","\n","\n","# Compile the model\n","dropout_model.compile(optimizer='SGD', \n","                      loss='categorical_crossentropy', \n","                      metrics=['acc'])\n","\n","# Train the model\n","dropout_model_val = dropout_model.fit(X_train_tokens, \n","                                      y_train_lb, \n","                                      epochs=150, \n","                                      batch_size=256, \n","                                      validation_data=(X_val_tokens, y_val_lb))"]},{"cell_type":"code","execution_count":92,"metadata":{"scrolled":true},"outputs":[{"name":"stdout","output_type":"stream","text":["235/235 [==============================] - 0s 737us/step - loss: 1.9278 - acc: 0.1884\n","Training Loss: 1.93 \n","Training Accuracy: 0.188\n","----------\n","47/47 [==============================] - 0s 462us/step - loss: 1.9275 - acc: 0.1940\n","Test Loss: 1.93 \n","Test Accuracy: 0.194\n"]}],"source":["results_train = dropout_model.evaluate(X_train_tokens, y_train_lb)\n","print(f'Training Loss: {results_train[0]:.3} \\nTraining Accuracy: {results_train[1]:.3}')\n","\n","print('----------')\n","\n","results_test = dropout_model.evaluate(X_test_tokens, y_test_lb)\n","print(f'Test Loss: {results_test[0]:.3} \\nTest Accuracy: {results_test[1]:.3}') "]},{"cell_type":"markdown","metadata":{},"source":["You can see here that the validation performance has improved again, and the training and test accuracy are very close!  \n","\n","## Bigger Data? \n","\n","Finally, let's examine if we can improve the model's performance just by adding more data. We've quadrapled the sample dataset from 10,000 to 40,000 observations, and all you need to do is run the code! "]},{"cell_type":"code","execution_count":93,"metadata":{},"outputs":[],"source":["df_bigger_sample = df.sample(40000, random_state=123)\n","\n","X = df['Consumer complaint narrative']\n","y = df['Product']\n","\n","# Train-test split\n","X_train_bigger, X_test_bigger, y_train_bigger, y_test_bigger = train_test_split(X, \n","                                                                                y, \n","                                                                                test_size=6000, \n","                                                                                random_state=42)\n","\n","# Validation set\n","X_train_final_bigger, X_val_bigger, y_train_final_bigger, y_val_bigger = train_test_split(X_train_bigger, \n","                                                                                          y_train_bigger, \n","                                                                                          test_size=4000, \n","                                                                                          random_state=42)\n","\n","\n","# One-hot encoding of the complaints\n","tokenizer = Tokenizer(num_words=2000)\n","tokenizer.fit_on_texts(X_train_final_bigger)\n","\n","X_train_tokens_bigger = tokenizer.texts_to_matrix(X_train_final_bigger, mode='binary')\n","X_val_tokens_bigger = tokenizer.texts_to_matrix(X_val_bigger, mode='binary')\n","X_test_tokens_bigger = tokenizer.texts_to_matrix(X_test_bigger, mode='binary')\n","\n","# One-hot encoding of products\n","lb = LabelBinarizer()\n","lb.fit(y_train_final_bigger)\n","\n","y_train_lb_bigger = to_categorical(lb.transform(y_train_final_bigger))[:, :, 1]\n","y_val_lb_bigger = to_categorical(lb.transform(y_val_bigger))[:, :, 1]\n","y_test_lb_bigger = to_categorical(lb.transform(y_test_bigger))[:, :, 1]"]},{"cell_type":"code","execution_count":94,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/150\n","196/196 [==============================] - 1s 4ms/step - loss: 1.8974 - acc: 0.2119 - val_loss: 1.8328 - val_acc: 0.2660\n","Epoch 2/150\n","196/196 [==============================] - 1s 4ms/step - loss: 1.7138 - acc: 0.3945 - val_loss: 1.5815 - val_acc: 0.4947\n","Epoch 3/150\n","196/196 [==============================] - 1s 3ms/step - loss: 1.4169 - acc: 0.5564 - val_loss: 1.2715 - val_acc: 0.6083\n","Epoch 4/150\n","196/196 [==============================] - 1s 3ms/step - loss: 1.1495 - acc: 0.6360 - val_loss: 1.0529 - val_acc: 0.6635\n","Epoch 5/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.9731 - acc: 0.6831 - val_loss: 0.9162 - val_acc: 0.6942\n","Epoch 6/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.8578 - acc: 0.7121 - val_loss: 0.8257 - val_acc: 0.7240\n","Epoch 7/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.7801 - acc: 0.7309 - val_loss: 0.7668 - val_acc: 0.7385\n","Epoch 8/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.7262 - acc: 0.7448 - val_loss: 0.7260 - val_acc: 0.7490\n","Epoch 9/150\n","196/196 [==============================] - 1s 4ms/step - loss: 0.6871 - acc: 0.7549 - val_loss: 0.6975 - val_acc: 0.7515\n","Epoch 10/150\n","196/196 [==============================] - 1s 4ms/step - loss: 0.6576 - acc: 0.7641 - val_loss: 0.6755 - val_acc: 0.7580\n","Epoch 11/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.6344 - acc: 0.7706 - val_loss: 0.6591 - val_acc: 0.7610\n","Epoch 12/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.6154 - acc: 0.7762 - val_loss: 0.6439 - val_acc: 0.7688\n","Epoch 13/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.5997 - acc: 0.7819 - val_loss: 0.6343 - val_acc: 0.7747\n","Epoch 14/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.5860 - acc: 0.7870 - val_loss: 0.6246 - val_acc: 0.7753\n","Epoch 15/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.5739 - acc: 0.7919 - val_loss: 0.6197 - val_acc: 0.7738\n","Epoch 16/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.5637 - acc: 0.7957 - val_loss: 0.6129 - val_acc: 0.7785\n","Epoch 17/150\n","196/196 [==============================] - 0s 3ms/step - loss: 0.5542 - acc: 0.7983 - val_loss: 0.6046 - val_acc: 0.7810\n","Epoch 18/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.5453 - acc: 0.8021 - val_loss: 0.5972 - val_acc: 0.7818\n","Epoch 19/150\n","196/196 [==============================] - 0s 3ms/step - loss: 0.5371 - acc: 0.8057 - val_loss: 0.5990 - val_acc: 0.7793\n","Epoch 20/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.5298 - acc: 0.8084 - val_loss: 0.5862 - val_acc: 0.7865\n","Epoch 21/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.5227 - acc: 0.8102 - val_loss: 0.5856 - val_acc: 0.7845\n","Epoch 22/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.5160 - acc: 0.8135 - val_loss: 0.5791 - val_acc: 0.7878\n","Epoch 23/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.5100 - acc: 0.8157 - val_loss: 0.5764 - val_acc: 0.7910\n","Epoch 24/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.5042 - acc: 0.8171 - val_loss: 0.5752 - val_acc: 0.7918\n","Epoch 25/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.4987 - acc: 0.8194 - val_loss: 0.5699 - val_acc: 0.7958\n","Epoch 26/150\n","196/196 [==============================] - 0s 3ms/step - loss: 0.4933 - acc: 0.8222 - val_loss: 0.5669 - val_acc: 0.7950\n","Epoch 27/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.4884 - acc: 0.8248 - val_loss: 0.5632 - val_acc: 0.7962\n","Epoch 28/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.4838 - acc: 0.8259 - val_loss: 0.5626 - val_acc: 0.7983\n","Epoch 29/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.4793 - acc: 0.8283 - val_loss: 0.5575 - val_acc: 0.8000\n","Epoch 30/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.4749 - acc: 0.8300 - val_loss: 0.5571 - val_acc: 0.8000\n","Epoch 31/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.4709 - acc: 0.8311 - val_loss: 0.5573 - val_acc: 0.8035\n","Epoch 32/150\n","196/196 [==============================] - 1s 4ms/step - loss: 0.4669 - acc: 0.8331 - val_loss: 0.5522 - val_acc: 0.8048\n","Epoch 33/150\n","196/196 [==============================] - 1s 4ms/step - loss: 0.4630 - acc: 0.8348 - val_loss: 0.5534 - val_acc: 0.8035\n","Epoch 34/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.4594 - acc: 0.8372 - val_loss: 0.5517 - val_acc: 0.8060\n","Epoch 35/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.4559 - acc: 0.8381 - val_loss: 0.5495 - val_acc: 0.8077\n","Epoch 36/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.4524 - acc: 0.8399 - val_loss: 0.5513 - val_acc: 0.8010\n","Epoch 37/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.4491 - acc: 0.8397 - val_loss: 0.5481 - val_acc: 0.8043\n","Epoch 38/150\n","196/196 [==============================] - 0s 2ms/step - loss: 0.4456 - acc: 0.8424 - val_loss: 0.5472 - val_acc: 0.8043\n","Epoch 39/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.4428 - acc: 0.8432 - val_loss: 0.5470 - val_acc: 0.8055\n","Epoch 40/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.4396 - acc: 0.8441 - val_loss: 0.5458 - val_acc: 0.8062\n","Epoch 41/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.4371 - acc: 0.8450 - val_loss: 0.5456 - val_acc: 0.8105\n","Epoch 42/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.4343 - acc: 0.8460 - val_loss: 0.5443 - val_acc: 0.8035\n","Epoch 43/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.4317 - acc: 0.8470 - val_loss: 0.5435 - val_acc: 0.8075\n","Epoch 44/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.4291 - acc: 0.8484 - val_loss: 0.5439 - val_acc: 0.8045\n","Epoch 45/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.4265 - acc: 0.8495 - val_loss: 0.5439 - val_acc: 0.8098\n","Epoch 46/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.4243 - acc: 0.8503 - val_loss: 0.5400 - val_acc: 0.8095\n","Epoch 47/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.4212 - acc: 0.8515 - val_loss: 0.5430 - val_acc: 0.8102\n","Epoch 48/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.4193 - acc: 0.8523 - val_loss: 0.5469 - val_acc: 0.8043\n","Epoch 49/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.4171 - acc: 0.8529 - val_loss: 0.5409 - val_acc: 0.8077\n","Epoch 50/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.4149 - acc: 0.8532 - val_loss: 0.5380 - val_acc: 0.8110\n","Epoch 51/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.4128 - acc: 0.8548 - val_loss: 0.5379 - val_acc: 0.8117\n","Epoch 52/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.4103 - acc: 0.8555 - val_loss: 0.5376 - val_acc: 0.8135\n","Epoch 53/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.4083 - acc: 0.8564 - val_loss: 0.5381 - val_acc: 0.8067\n","Epoch 54/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.4065 - acc: 0.8570 - val_loss: 0.5415 - val_acc: 0.8115\n","Epoch 55/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.4041 - acc: 0.8577 - val_loss: 0.5379 - val_acc: 0.8108\n","Epoch 56/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.4022 - acc: 0.8584 - val_loss: 0.5375 - val_acc: 0.8138\n","Epoch 57/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.4005 - acc: 0.8588 - val_loss: 0.5353 - val_acc: 0.8125\n","Epoch 58/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.3988 - acc: 0.8600 - val_loss: 0.5386 - val_acc: 0.8115\n","Epoch 59/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.3966 - acc: 0.8602 - val_loss: 0.5396 - val_acc: 0.8108\n","Epoch 60/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.3950 - acc: 0.8607 - val_loss: 0.5378 - val_acc: 0.8095\n","Epoch 61/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.3933 - acc: 0.8614 - val_loss: 0.5394 - val_acc: 0.8085\n","Epoch 62/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.3915 - acc: 0.8623 - val_loss: 0.5385 - val_acc: 0.8110\n","Epoch 63/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.3901 - acc: 0.8629 - val_loss: 0.5362 - val_acc: 0.8108\n","Epoch 64/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.3884 - acc: 0.8637 - val_loss: 0.5381 - val_acc: 0.8142\n","Epoch 65/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.3866 - acc: 0.8640 - val_loss: 0.5404 - val_acc: 0.8110\n","Epoch 66/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.3852 - acc: 0.8637 - val_loss: 0.5387 - val_acc: 0.8142\n","Epoch 67/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.3836 - acc: 0.8651 - val_loss: 0.5399 - val_acc: 0.8138\n","Epoch 68/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.3818 - acc: 0.8654 - val_loss: 0.5388 - val_acc: 0.8155\n","Epoch 69/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.3804 - acc: 0.8661 - val_loss: 0.5410 - val_acc: 0.8080\n","Epoch 70/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.3790 - acc: 0.8667 - val_loss: 0.5401 - val_acc: 0.8120\n","Epoch 71/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.3773 - acc: 0.8673 - val_loss: 0.5392 - val_acc: 0.8135\n","Epoch 72/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.3761 - acc: 0.8669 - val_loss: 0.5408 - val_acc: 0.8112\n","Epoch 73/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.3749 - acc: 0.8683 - val_loss: 0.5388 - val_acc: 0.8148\n","Epoch 74/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.3731 - acc: 0.8687 - val_loss: 0.5404 - val_acc: 0.8125\n","Epoch 75/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.3719 - acc: 0.8684 - val_loss: 0.5470 - val_acc: 0.8085\n","Epoch 76/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.3704 - acc: 0.8696 - val_loss: 0.5433 - val_acc: 0.8087\n","Epoch 77/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.3694 - acc: 0.8696 - val_loss: 0.5471 - val_acc: 0.8125\n","Epoch 78/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.3679 - acc: 0.8706 - val_loss: 0.5483 - val_acc: 0.8112\n","Epoch 79/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.3667 - acc: 0.8709 - val_loss: 0.5402 - val_acc: 0.8117\n","Epoch 80/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.3656 - acc: 0.8711 - val_loss: 0.5417 - val_acc: 0.8133\n","Epoch 81/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.3641 - acc: 0.8721 - val_loss: 0.5454 - val_acc: 0.8098\n","Epoch 82/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.3630 - acc: 0.8726 - val_loss: 0.5425 - val_acc: 0.8148\n","Epoch 83/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.3617 - acc: 0.8719 - val_loss: 0.5499 - val_acc: 0.8095\n","Epoch 84/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.3602 - acc: 0.8729 - val_loss: 0.5468 - val_acc: 0.8125\n","Epoch 85/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.3596 - acc: 0.8736 - val_loss: 0.5480 - val_acc: 0.8102\n","Epoch 86/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.3581 - acc: 0.8741 - val_loss: 0.5475 - val_acc: 0.8087\n","Epoch 87/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.3569 - acc: 0.8749 - val_loss: 0.5521 - val_acc: 0.8112\n","Epoch 88/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.3557 - acc: 0.8748 - val_loss: 0.5458 - val_acc: 0.8080\n","Epoch 89/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.3546 - acc: 0.8744 - val_loss: 0.5473 - val_acc: 0.8123\n","Epoch 90/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.3533 - acc: 0.8759 - val_loss: 0.5473 - val_acc: 0.8095\n","Epoch 91/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.3523 - acc: 0.8760 - val_loss: 0.5523 - val_acc: 0.8125\n","Epoch 92/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.3514 - acc: 0.8765 - val_loss: 0.5466 - val_acc: 0.8135\n","Epoch 93/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.3500 - acc: 0.8766 - val_loss: 0.5467 - val_acc: 0.8112\n","Epoch 94/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.3490 - acc: 0.8777 - val_loss: 0.5500 - val_acc: 0.8108\n","Epoch 95/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.3482 - acc: 0.8774 - val_loss: 0.5541 - val_acc: 0.8090\n","Epoch 96/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.3472 - acc: 0.8783 - val_loss: 0.5507 - val_acc: 0.8115\n","Epoch 97/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.3461 - acc: 0.8777 - val_loss: 0.5491 - val_acc: 0.8138\n","Epoch 98/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.3448 - acc: 0.8784 - val_loss: 0.5559 - val_acc: 0.8075\n","Epoch 99/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.3439 - acc: 0.8787 - val_loss: 0.5538 - val_acc: 0.8077\n","Epoch 100/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.3427 - acc: 0.8800 - val_loss: 0.5514 - val_acc: 0.8112\n","Epoch 101/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.3416 - acc: 0.8806 - val_loss: 0.5543 - val_acc: 0.8100\n","Epoch 102/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.3410 - acc: 0.8801 - val_loss: 0.5533 - val_acc: 0.8073\n","Epoch 103/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.3394 - acc: 0.8812 - val_loss: 0.5557 - val_acc: 0.8125\n","Epoch 104/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.3388 - acc: 0.8810 - val_loss: 0.5579 - val_acc: 0.8090\n","Epoch 105/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.3378 - acc: 0.8814 - val_loss: 0.5613 - val_acc: 0.8030\n","Epoch 106/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.3368 - acc: 0.8823 - val_loss: 0.5545 - val_acc: 0.8102\n","Epoch 107/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.3356 - acc: 0.8824 - val_loss: 0.5622 - val_acc: 0.8023\n","Epoch 108/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.3352 - acc: 0.8822 - val_loss: 0.5618 - val_acc: 0.8095\n","Epoch 109/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.3338 - acc: 0.8827 - val_loss: 0.5558 - val_acc: 0.8105\n","Epoch 110/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.3332 - acc: 0.8837 - val_loss: 0.5555 - val_acc: 0.8115\n","Epoch 111/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.3319 - acc: 0.8833 - val_loss: 0.5640 - val_acc: 0.8052\n","Epoch 112/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.3312 - acc: 0.8838 - val_loss: 0.5636 - val_acc: 0.8060\n","Epoch 113/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.3303 - acc: 0.8844 - val_loss: 0.5613 - val_acc: 0.8133\n","Epoch 114/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.3293 - acc: 0.8843 - val_loss: 0.5617 - val_acc: 0.8098\n","Epoch 115/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.3283 - acc: 0.8847 - val_loss: 0.5643 - val_acc: 0.8087\n","Epoch 116/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.3274 - acc: 0.8854 - val_loss: 0.5633 - val_acc: 0.8070\n","Epoch 117/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.3263 - acc: 0.8867 - val_loss: 0.5664 - val_acc: 0.8102\n","Epoch 118/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.3255 - acc: 0.8865 - val_loss: 0.5629 - val_acc: 0.8105\n","Epoch 119/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.3248 - acc: 0.8869 - val_loss: 0.5674 - val_acc: 0.8102\n","Epoch 120/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.3239 - acc: 0.8864 - val_loss: 0.5625 - val_acc: 0.8067\n","Epoch 121/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.3228 - acc: 0.8881 - val_loss: 0.5637 - val_acc: 0.8055\n","Epoch 122/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.3220 - acc: 0.8872 - val_loss: 0.5664 - val_acc: 0.8087\n","Epoch 123/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.3213 - acc: 0.8876 - val_loss: 0.5755 - val_acc: 0.8045\n","Epoch 124/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.3201 - acc: 0.8885 - val_loss: 0.5702 - val_acc: 0.8052\n","Epoch 125/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.3191 - acc: 0.8885 - val_loss: 0.5722 - val_acc: 0.8045\n","Epoch 126/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.3187 - acc: 0.8881 - val_loss: 0.5684 - val_acc: 0.8070\n","Epoch 127/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.3176 - acc: 0.8896 - val_loss: 0.5692 - val_acc: 0.8048\n","Epoch 128/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.3164 - acc: 0.8893 - val_loss: 0.5711 - val_acc: 0.8112\n","Epoch 129/150\n","196/196 [==============================] - 0s 2ms/step - loss: 0.3157 - acc: 0.8896 - val_loss: 0.5701 - val_acc: 0.8075\n","Epoch 130/150\n","196/196 [==============================] - 0s 3ms/step - loss: 0.3148 - acc: 0.8903 - val_loss: 0.5702 - val_acc: 0.8055\n","Epoch 131/150\n","196/196 [==============================] - 0s 3ms/step - loss: 0.3140 - acc: 0.8902 - val_loss: 0.5744 - val_acc: 0.8090\n","Epoch 132/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.3131 - acc: 0.8906 - val_loss: 0.5759 - val_acc: 0.8077\n","Epoch 133/150\n","196/196 [==============================] - 0s 2ms/step - loss: 0.3124 - acc: 0.8906 - val_loss: 0.5757 - val_acc: 0.8055\n","Epoch 134/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.3113 - acc: 0.8914 - val_loss: 0.5762 - val_acc: 0.8075\n","Epoch 135/150\n","196/196 [==============================] - 0s 2ms/step - loss: 0.3105 - acc: 0.8915 - val_loss: 0.5835 - val_acc: 0.8085\n","Epoch 136/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.3096 - acc: 0.8918 - val_loss: 0.5866 - val_acc: 0.8062\n","Epoch 137/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.3086 - acc: 0.8927 - val_loss: 0.5799 - val_acc: 0.8060\n","Epoch 138/150\n","196/196 [==============================] - 0s 3ms/step - loss: 0.3077 - acc: 0.8926 - val_loss: 0.5929 - val_acc: 0.7985\n","Epoch 139/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.3069 - acc: 0.8929 - val_loss: 0.5793 - val_acc: 0.8087\n","Epoch 140/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.3060 - acc: 0.8935 - val_loss: 0.5784 - val_acc: 0.8048\n","Epoch 141/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.3053 - acc: 0.8931 - val_loss: 0.5782 - val_acc: 0.8070\n","Epoch 142/150\n","196/196 [==============================] - 0s 2ms/step - loss: 0.3039 - acc: 0.8948 - val_loss: 0.5862 - val_acc: 0.8030\n","Epoch 143/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.3036 - acc: 0.8944 - val_loss: 0.5892 - val_acc: 0.8045\n","Epoch 144/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.3026 - acc: 0.8949 - val_loss: 0.5888 - val_acc: 0.8055\n","Epoch 145/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.3017 - acc: 0.8957 - val_loss: 0.5862 - val_acc: 0.8067\n","Epoch 146/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.3006 - acc: 0.8958 - val_loss: 0.5831 - val_acc: 0.8090\n","Epoch 147/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.2998 - acc: 0.8961 - val_loss: 0.6000 - val_acc: 0.8018\n","Epoch 148/150\n","196/196 [==============================] - 0s 2ms/step - loss: 0.2991 - acc: 0.8968 - val_loss: 0.5906 - val_acc: 0.8077\n","Epoch 149/150\n","196/196 [==============================] - 1s 3ms/step - loss: 0.2979 - acc: 0.8964 - val_loss: 0.5855 - val_acc: 0.8043\n","Epoch 150/150\n","196/196 [==============================] - 0s 2ms/step - loss: 0.2971 - acc: 0.8964 - val_loss: 0.5886 - val_acc: 0.8060\n"]}],"source":["# ⏰ This cell may take several minutes to run\n","random.seed(123)\n","bigger_data_model = models.Sequential()\n","bigger_data_model.add(layers.Dense(50, activation='relu', input_shape=(2000,)))\n","bigger_data_model.add(layers.Dense(25, activation='relu'))\n","bigger_data_model.add(layers.Dense(7, activation='softmax'))\n","\n","bigger_data_model.compile(optimizer='SGD', \n","                          loss='categorical_crossentropy', \n","                          metrics=['acc'])\n","\n","bigger_data_model_val = bigger_data_model.fit(X_train_tokens_bigger,  \n","                                              y_train_lb_bigger,  \n","                                              epochs=150,  \n","                                              batch_size=256,  \n","                                              validation_data=(X_val_tokens_bigger, y_val_lb_bigger))"]},{"cell_type":"code","execution_count":95,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1563/1563 [==============================] - 1s 544us/step - loss: 0.2909 - acc: 0.9003\n","Training Loss: 0.291 \n","Training Accuracy: 0.9\n","----------\n","125/125 [==============================] - 0s 794us/step - loss: 0.5886 - acc: 0.8060\n","Test Loss: 0.589 \n","Test Accuracy: 0.806\n"]}],"source":["results_train = bigger_data_model.evaluate(X_train_tokens_bigger, y_train_lb_bigger)\n","print(f'Training Loss: {results_train[0]:.3} \\nTraining Accuracy: {results_train[1]:.3}')\n","\n","print('----------')\n","\n","results_test = bigger_data_model.evaluate(X_val_tokens_bigger, y_val_lb_bigger)\n","print(f'Test Loss: {results_test[0]:.3} \\nTest Accuracy: {results_test[1]:.3}')"]},{"cell_type":"markdown","metadata":{},"source":["With the same amount of epochs and no regularization technique, you were able to get both better test accuracy and loss. You can still consider early stopping, L1, L2 and dropout here. It's clear that having more data has a strong impact on model performance! \n","\n","\n","## Additional Resources\n","\n","* https://github.com/susanli2016/Machine-Learning-with-Python/blob/master/Consumer_complaints.ipynb\n","* https://machinelearningmastery.com/dropout-regularization-deep-learning-models-keras/\n","* https://catalog.data.gov/dataset/consumer-complaint-database \n","\n","\n","## Summary  \n","\n","In this lesson, you built deep learning models using a validation set and used several techniques such as L2 and L1 regularization, dropout regularization, and early stopping to improve the accuracy of your models. "]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false}},"nbformat":4,"nbformat_minor":2}
